### YamlMime:FAQ
metadata:
  title: Häufig gestellte Fragen (FAQ) – Personalizer
  description: Dieser Artikel enthält Antworten auf Fragen zur Behandlung von Problemen mit Personalizer.
  ms.service: cognitive-services
  ms.subservice: personalizer
  ms.topic: troubleshooting
  ms.date: 02/26/2020
  ms.author: jeffme
  author: jeffmend
  ms.manager: nitinme
  ms.openlocfilehash: 13e935fabd4b80148ef27f19bf4173ff722a6db6
  ms.sourcegitcommit: 16e25fb3a5fa8fc054e16f30dc925a7276f2a4cb
  ms.translationtype: HT
  ms.contentlocale: de-DE
  ms.lasthandoff: 08/25/2021
  ms.locfileid: "122831422"
title: 'Personalizer: Häufig gestellte Fragen'
summary: Dieser Artikel enthält Antworten auf Fragen zur Behandlung von Problemen mit dem Personalizer-Dienst.
sections:
- name: Konfigurationsprobleme
  questions:
  - question: >
      Ich habe eine Konfigurationseinstellung geändert, und jetzt erreicht meine Schleife nicht dieselbe Lernebene. Was ist passiert?
    answer: >
      Einige Konfigurationseinstellungen [setzen Ihr Modell zurück](how-to-settings.md#settings-that-include-resetting-the-model). Konfigurationsänderungen sollten sorgfältig geplant werden.
  - question: >
      Beim Konfigurieren der Personalisierung über die API habe ich einen Fehler erhalten. Was ist passiert?
    answer: >
      Wenn Sie eine einzelne API-Anforderung verwenden, um Ihren Dienst zu konfigurieren und Ihr Lernverhalten zu ändern, erhalten Sie eine Fehlermeldung. Sie müssen zwei separate API-Aufrufe durchführen. Mit dem ersten Aufruf konfigurieren Sie Ihren Dienst, und mit dem zweiten Aufruf ändern Sie das Lernverhalten.
- name: Transaktionsfehler
  questions:
  - question: >
      Ich erhalte die Antwort „HTTP 429 (Zu viele Anforderungen) vom Dienst. Was kann ich tun?
    answer: >
      Wenn Sie beim Erstellen der Personalisierungsinstanz einen kostenlosen Tarif ausgewählt haben, besteht ein Kontingentlimit für die Anzahl von zulässigen Ranganforderungen. Überprüfen Sie die API-Aufrufquote für die Rang-API (im Azure-Portal für Ihre Personalisierungsressource im Bereich „Metriken“), und passen Sie den Tarif an (im Bereich „Tarif“), wenn Sie damit rechnen, dass das Aufrufvolumen über den Schwellenwert für den ausgewählten Tarif hinaus anwächst.
  - question: >
      Ich erhalte einen 5xx-Fehler bei Rang- oder Belohnungs-APIs. Wie sollte ich vorgehen?
    answer: >
      Diese Probleme sollten vorübergehend sein. Falls sie weiterhin auftreten, wenden Sie sich an den Support, indem Sie im Azure-Portal für Ihre Personalisierungsressource im Abschnitt **Support und Problembehandlung** die Option **Neue Supportanfrage** auswählen.
- name: Lernschleife
  questions:
  - question: >
      Die Lernschleife erreicht ohne Personalisierung keine 100 %ige Übereinstimmung mit dem System. Wie kann ich dies korrigieren?
    answer: >
      Die Gründe, warum Sie Ihr Ziel mit der Lernschleife nicht erreichen:

      * Nicht ausreichend Features mit dem Rang-API-Aufruf gesendet

      * Fehler in den gesendeten Features – z. B. das Senden von nicht aggregierten Featuredaten wie Zeitstempel an die Rang-API

      * Fehler bei der Schleifenverarbeitung – z. B. kein Senden von Relevanzdaten an die Relevanz-API für Ereignisse


      Um das Problem zu beheben, müssen Sie die Verarbeitung ändern, indem Sie entweder die an die Schleife gesendeten Features ändern oder sicherstellen, dass die Relevanz eine korrekte Bewertung der Qualität der Antwort des Rangs ist.
  - question: >
      Die Lernschleife funktioniert anscheinend nicht. Wie kann ich dies korrigieren?
    answer: >
      Die Lernschleife benötigt einige Tausend Belohnungsaufrufe, bevor Priorisierungsaufrufe effektiv priorisiert werden.


      Wenn Sie sich nicht sicher sind, wie Ihre Lernschleife sich derzeit verhält, führen Sie eine [Offlineauswertung](concepts-offline-evaluation.md) aus, und wenden Sie die korrigierte Lernrichtlinie an.
  - question: >
      Ich erhalte immer wieder Rangergebnisse mit der gleichen Wahrscheinlichkeit für alle Elemente. Woher weiß ich, ob die Personalisierung lernt?
    answer: >
      Die Personalisierung gibt die gleichen Wahrscheinlichkeiten in einem Rang-API-Ergebnis zurück, wenn die API gerade gestartet wurde und mit einem _leeren_ Modell arbeitet. Dies ist auch der Fall, wenn Sie die Personalisierungsschleife zurücksetzen und das Modell sich noch im Zeitraum **Aktualisierungshäufigkeit des Modells** befindet.


      Wenn ein neuer Aktualisierungszeitraum beginnt, wird das aktualisierte Modell verwendet, und Sie werden feststellen, dass sich die Wahrscheinlichkeiten ändern.
  - question: >
      In der Lernschleife fand ein Lernprozess statt, dies scheint aber nicht mehr der Fall zu sein, und die Qualität der Rangergebnisse ist nicht besonders gut. Wie sollte ich vorgehen?
    answer: >
      * Stellen Sie sicher, dass Sie im Azure-Portal eine vollständige Auswertung für diese Personalisierungsressource abgeschlossen und angewendet haben (Lernschleife).

      * Stellen Sie sicher, dass alle Belohnungen über die Belohnungs-API gesendet und verarbeitet wurden.
  - question: >
      Woher weiß ich, ob die Lernschleife regelmäßig aktualisiert und zum Bewerten meiner Daten verwendet wird?
    answer: >
      Sie finden den Zeitpunkt der letzten Aktualisierung des Modells auf der Seite **Modell- und Lerneinstellungen** im Azure-Portal. Wenn dort ein älterer Zeitstempel angezeigt wird, ist es wahrscheinlich, dass die Rang- und Belohnungsaufrufe nicht gesendet werden. Wenn der Dienst keine eingehenden Daten feststellt, aktualisiert er den Lernvorgang nicht. Wenn Sie der Ansicht sind, dass die Lernschleife nicht häufig genug aktualisiert wird, können Sie die **Aktualisierungshäufigkeit des Modells** bearbeiten.
- name: Offlineauswertungen
  questions:
  - question: >
      Die Featurerelevanz einer Offlineauswertung gibt eine lange Liste mit Hunderttausenden von Elementen zurück. Was ist passiert?
    answer: >
      Dies liegt in der Regel an Zeitstempeln, Benutzer-IDs oder anderen differenzierten Merkmalen, die gesendet wurden.
  - question: >
      Ich habe eine Offlineauswertung erstellt, und sie wurde fast sofort erfolgreich ausgeführt. Warum? Es werden keine Ergebnisse angezeigt.
    answer: >
      Die Offlineauswertung verwendet die trainierten Modelldaten aus den Ereignissen in diesem Zeitraum. Wenn Sie zwischen dem Start- und Endzeitpunkt der Auswertung keine Daten gesendet haben, wird die Auswertung ohne Ergebnisse abgeschlossen. Starten Sie eine neue Offlineauswertung, indem Sie einen Zeitbereich mit Ereignissen auswählen, von denen Sie wissen, dass sie an die Personalisierung gesendet wurden.
- name: Lernrichtlinie
  questions:
  - question: >
      Wie importiere ich eine Lernrichtlinie?
    answer: >
      Informieren Sie sich über [Konzepte von Lernrichtlinien](concept-active-learning.md#understand-learning-policy-settings) und die [Anwendung](how-to-manage-model.md) einer neuen Lernrichtlinie. Wenn Sie keine Lernrichtlinie auswählen möchten, können Sie eine [Offlineauswertung](how-to-offline-evaluation.md) verwenden, um basierend auf Ihren aktuellen Ereignissen eine Lernrichtlinie vorzuschlagen.
- name: Sicherheit
  questions:
  - question: >
      Der API-Schlüssel für meine Schleife wurde kompromittiert. Was kann ich tun?
    answer: >
      Sie können einen Schlüssel erneut generieren, nachdem Sie die Schlüsselverwendung durch die Clients getauscht haben. Wenn Sie über zwei Schlüssel verfügen, können Sie den Schlüssel verzögert weitergeben, ohne dass Ausfallzeiten auftreten. Wir empfehlen einen regelmäßigen Tausch als Sicherheitsmaßnahme.
additionalContent: "\n## <a name=\"next-steps\"></a>Nächste Schritte\n\n[Configure the model update frequency (Ändern der Häufigkeit der Modellaktualisierung)](how-to-settings.md#model-update-frequency)"

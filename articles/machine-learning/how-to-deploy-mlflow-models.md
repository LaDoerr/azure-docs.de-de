---
title: Bereitstellen von MLflow-Modellen als Webdienst
titleSuffix: Azure Machine Learning
description: Richten Sie MLflow mit Azure Machine Learning ein, um Ihre ML-Modelle als Azure-Webdienst bereitzustellen.
services: machine-learning
author: cjgronlund
ms.author: cgronlun
ms.service: machine-learning
ms.subservice: core
ms.reviewer: nibaccam
ms.date: 05/25/2021
ms.topic: how-to
ms.custom: devx-track-python
ms.openlocfilehash: c5dd42aa86b661fc6b1174cf0834610168d92f4c
ms.sourcegitcommit: 0770a7d91278043a83ccc597af25934854605e8b
ms.translationtype: HT
ms.contentlocale: de-DE
ms.lasthandoff: 09/13/2021
ms.locfileid: "124819429"
---
# <a name="deploy-mlflow-models-as-azure-web-services"></a>Bereitstellen von MLflow-Modellen als Azure-Webdienste

In diesem Artikel erfahren Sie, wie Sie Ihr [MLflow](https://www.mlflow.org)-Modell als Azure-Webdienst bereitstellen, um die Azure Machine Learning-Funktionen für die Modellverwaltung und Datendrifterkennung nutzen und auf Ihre Produktionsmodelle anwenden zu können. Weitere Informationen zur Integration von MLflow- und Azure Machine Learning-Funktionen finden Sie unter [MLflow und Azure Machine Learning](concept-mlflow.md).

Azure Machine Learning bietet Bereitstellungskonfigurationen für Folgendes:
* Azure Container Instance (ACI) ist eine geeignete Wahl für die schnelle Bereitstellung von Dev/Test-Funktionen.
* Azure Kubernetes Service (AKS) empfiehlt sich für skalierbare Produktionsbereitstellungen.

[!INCLUDE [endpoints-option](../../includes/machine-learning-endpoints-preview-note.md)]

> [!TIP]
> Dieses Dokument richtet sich primär an Data Scientists und Entwickler, die ihr MLflow-Modell an einem Azure Machine Learning-Webdienstendpunkt bereitstellen möchten. Wenn Sie Administrator sind und sich für die Überwachung der Nutzung und Ereignisse von Azure Machine Learning (z. B. Kontingente, abgeschlossene Trainingsausführungen oder abgeschlossene Modellimplementierungen) interessieren, helfen Ihnen die Informationen im Artikel [Überwachen von Azure Machine Learning](monitor-azure-machine-learning.md) weiter.

## <a name="mlflow-with-azure-machine-learning-deployment"></a>Bereitstellung von MLflow mit Azure Machine Learning

MLFlow ist eine Open-Source-Bibliothek zum Verwalten des Lebenszyklus Ihrer Machine Learning-Experimente. Dank der Integration in Azure Machine Learning können Sie von der Modelltrainingsphase bis hin zur Bereitstellungsphase Ihres Produktionsmodells von diesen Verwaltungsfunktionen profitieren.

Das folgende Diagramm veranschaulicht, wie Sie mit der MLflow-Bereitstellungs-API und Azure Machine Learning mit beliebten Frameworks (PyTorch, Tensorflow, scikit-learn usw.) erstellte Modelle als Azure-Webdienst bereitstellen und im Arbeitsbereich verwalten können. 

![ Bereitstellen von MLflow-Modellen mit Azure Machine Learning](./media/how-to-deploy-mlflow-models/mlflow-diagram-deploy.png)

## <a name="prerequisites"></a>Voraussetzungen

* Ein Machine Learning-Modell. Wenn Sie über kein trainiertes Modell verfügen, suchen Sie in [diesem Repository](https://github.com/Azure/MachineLearningNotebooks/tree/master/how-to-use-azureml/ml-frameworks/using-mlflow) das Notebook, das sich am besten für Ihr Computeszenario eignet, und befolgen Sie die Anweisungen. 
* [Richten Sie die MLflow-Nachverfolgungs-URI für die Verbindung mit Azure Machine Learning ein](how-to-use-mlflow.md#track-local-runs).
* Installieren Sie das `azureml-mlflow`-Paket. 
    * Mit diesem Paket wird automatisch `azureml-core` des [The Azure Machine Learning Python SDK](/python/api/overview/azure/ml/install) bereitgestellt, um MLflow den Zugriff auf Ihren Arbeitsbereich zu ermöglichen.
* Überprüfen Sie, welche [Zugriffsberechtigungen Sie benötigen, um Ihre MLflow-Vorgänge mit Ihrem Arbeitsbereich](how-to-assign-roles.md#mlflow-operations) auszuführen. 

## <a name="deploy-to-azure-container-instance-aci"></a>Bereitstellen in Azure Container Instances (ACI)

Damit Sie Ihr MLflow-Modell in einem Azure Machine Learning-Webdienst bereitstellen können, muss das Modell mit der [MLflow-Nachverfolgungs-URI zum Herstellen der Verbindung mit Azure Machine Learning](how-to-use-mlflow.md) eingerichtet sein. 

Für die Bereitstellung in ACI müssen Sie keine Bereitstellungskonfiguration definieren. Der Dienst verwendet standardmäßig eine ACI-Bereitstellung, wenn keine Konfiguration bereitgestellt wird.
Dann können Sie das Modell mithilfe der [deploy](https://www.mlflow.org/docs/latest/python_api/mlflow.azureml.html#mlflow.azureml.deploy)-Methode von MLflow in einem einzigen Schritt für Azure Machine Learning registrieren und bereitstellen. 


```python
from mlflow.deployments import get_deploy_client

# set the tracking uri as the deployment client
client = get_deploy_client(mlflow.get_tracking_uri())

# set the model path 
model_path = "model"

# define the model path and the name is the service name
# the model gets registered automatically and a name is autogenerated using the "name" parameter below 
client.create_deployment(model_uri='runs:/{}/{}'.format(run.id, model_path),
                         name="mlflow-test-aci")
```

### <a name="customize-deployment-configuration"></a>Anpassen der Bereitstellungskonfiguration

Wenn Sie die Standardwerte nicht verwenden möchten, können Sie Ihre Bereitstellungskonfiguration in einer JSON-Datei für die Bereitstellungskonfiguration einrichten. Sie nutzt die Parameter der [deploy_configuration()](/python/api/azureml-core/azureml.core.webservice.aciwebservice#deploy-configuration-cpu-cores-none--memory-gb-none--tags-none--properties-none--description-none--location-none--auth-enabled-none--ssl-enabled-none--enable-app-insights-none--ssl-cert-pem-file-none--ssl-key-pem-file-none--ssl-cname-none--dns-name-label-none-)-Methode als Referenz. 

Sie müssen in Ihrer JSON-Datei für die Bereitstellungskonfiguration alle Bereitstellungskonfigurationsparameter in Form eines Wörterbuchs definieren. Im Folgenden finden Sie ein Beispiel. [Erfahren Sie mehr über den möglichen Inhalt Ihrer JSON-Datei für die Bereitstellungskonfiguration.](reference-azure-machine-learning-cli.md#azure-container-instance-deployment-configuration-schema)

```json
{"computeType": "aci",
 "containerResourceRequirements": {"cpu": 1, "memoryInGB": 1},
 "location": "eastus2"
}
```

Ihre JSON-Datei kann dann dazu verwendet werden, Ihre Bereitstellung zu erstellen.

```python
# set the deployment config
deploy_path = "deployment_config.json"
test_config = {'deploy-config-file': deploy_path}

client.create_deployment(model_uri='runs:/{}/{}'.format(run.id, model_path),
                         config=test_config,
                         name="mlflow-test-aci")                                       
```


## <a name="deploy-to-azure-kubernetes-service-aks"></a>Bereitstellen für Azure Kubernetes Service (AKS)

Damit Sie Ihr MLflow-Modell in einem Azure Machine Learning-Webdienst bereitstellen können, muss das Modell mit der [MLflow-Nachverfolgungs-URI zum Herstellen der Verbindung mit Azure Machine Learning](how-to-use-mlflow.md) eingerichtet sein. 

Zur Bereitstellung für AKS erstellen Sie zunächst einen AKS-Cluster. Erstellen Sie mit der [ComputeTarget.create()](/python/api/azureml-core/azureml.core.computetarget#create-workspace--name--provisioning-configuration-)-Methode einen AKS-Cluster. Die Erstellung eines neuen Clusters kann 20 bis 25 Minuten dauern.

```python
from azureml.core.compute import AksCompute, ComputeTarget

# Use the default configuration (can also provide parameters to customize)
prov_config = AksCompute.provisioning_configuration()

aks_name = 'aks-mlflow'

# Create the cluster
aks_target = ComputeTarget.create(workspace=ws, 
                                  name=aks_name, 
                                  provisioning_configuration=prov_config)

aks_target.wait_for_completion(show_output = True)

print(aks_target.provisioning_state)
print(aks_target.provisioning_errors)
```
Erstellen Sie eine JSON-Datei für die Bereitstellungskonfiguration mit den Werten der Methode [deploy_configuration()](/python/api/azureml-core/azureml.core.webservice.aks.aksservicedeploymentconfiguration#parameters) als Referenz. Jeder Bereitstellungskonfigurationsparameter muss einfach als Wörterbuch definiert werden. Im Anschluss sehen Sie ein Beispiel:

```json
{"computeType": "aks", "computeTargetName": "aks-mlflow"}
```

Dann können Sie das Modell mithilfe des [Bereitstellungsclients](https://www.mlflow.org/docs/latest/python_api/mlflow.deployments.html) von MLflow in einem einzigen Schritt registrieren und bereitstellen. 

```python
from mlflow.deployments import get_deploy_client

# set the tracking uri as the deployment client
client = get_deploy_client(mlflow.get_tracking_uri())

# set the model path 
model_path = "model"

# set the deployment config
deploy_path = "deployment_config.json"
test_config = {'deploy-config-file': deploy_path}

# define the model path and the name is the service name
# the model gets registered automatically and a name is autogenerated using the "name" parameter below 
client.create_deployment(model_uri='runs:/{}/{}'.format(run.id, model_path),
                         config=test_config,
                         name="mlflow-test-aci")
```

Die Bereitstellung des Diensts kann mehrere Minuten dauern.

## <a name="clean-up-resources"></a>Bereinigen von Ressourcen

Wenn Sie den bereitgestellten Webdienst nicht verwenden werden, löschen Sie ihn mithilfe von `service.delete()` von Ihrem Notebook.  Weitere Informationen finden Sie in der Dokumentation zu [WebService.delete()](/python/api/azureml-core/azureml.core.webservice%28class%29#delete--).

## <a name="example-notebooks"></a>Beispielnotebooks

In den [Notebooks „MLflow mit Azure Machine Learning“](https://github.com/Azure/MachineLearningNotebooks/tree/master/how-to-use-azureml/ml-frameworks/using-mlflow) werden die in diesem Artikel vorgestellten Konzepte weiter erläutert und demonstriert.

> [!NOTE]
> Ein Communityrepository mit Beispielen, die MLflow verwenden, finden Sie unter https://github.com/Azure/azureml-examples.

## <a name="next-steps"></a>Nächste Schritte

* [Verwalten Ihrer Modelle](concept-model-management-and-deployment.md)
* Überwachen Ihrer Produktionsmodelle auf [Datenabweichungen](./how-to-enable-data-collection.md)
* [Nachverfolgen von Azure Databricks-Ausführungen mit MLflow](how-to-use-mlflow-azure-databricks.md)

### YamlMime:FAQ
metadata:
  title: 'Azure Media Services: Häufig gestellte Fragen'
  description: Erhalten Sie Antworten auf häufig gestellte Fragen zu Azure Media Services.
  ms.service: media-services
  ms.custom: contperf-fy21q4
  ms.openlocfilehash: bbe5b0f1ca4536c5ce03803c6e1a5822bcacc78f
  ms.sourcegitcommit: 2eac9bd319fb8b3a1080518c73ee337123286fa2
  ms.translationtype: HT
  ms.contentlocale: de-DE
  ms.lasthandoff: 08/31/2021
  ms.locfileid: "123258357"
title: Häufig gestellte Fragen zu Azure Media Services
summary: Dieser Artikel bietet Antworten auf häufig gestellte Fragen zu Azure Media Services.
sections:
- name: Entwickeln mit SDKs
  questions:
  - question: Wo finde ich die Media Services-API und SDKs?
    answer: >
      Hier folgt eine Liste:

      - [OpenAPI-Spezifikation (Swagger)](https://aka.ms/ams-v3-rest-sdk)

      - [Azure-Befehlszeilenschnittstelle](/cli/azure/install-azure-cli)

      - [.NET](https://aka.ms/ams-v3-dotnet-sdk)

      - [Java](https://aka.ms/ams-v3-java-sdk)

      - [Python](https://aka.ms/ams-v3-python-sdk)

      - [Node.js](https://aka.ms/ams-v3-nodejs-sdk)

      - [Go](https://aka.ms/ams-v3-go-sdk)

      - [Ruby](https://aka.ms/ams-v3-ruby-sdk)
  - question: Sollte ich die Client-SDKs verwenden oder direkt in die REST-API schreiben?
    answer: >
      Es wird nicht empfohlen, die REST-API für Media Services direkt in Ihren eigenen Bibliothekscode einzuschließen, da Sie dazu für Produktionszwecke die vollständige Wiederholungslogik der Azure-Ressourcenverwaltung implementieren und verstehen müssten, wie Vorgänge mit langer Ausführungsdauer in APIs für die Azure-Ressourcenverwaltung verwaltet werden. Dies wird von den Client-SDKs für verschiedene Sprachen (.NET, Java, Typescript, Python, Ruby usw.) automatisch für Sie erledigt und verringert die Wahrscheinlichkeit, dass Probleme mit der Wiederholungslogik oder mit fehlgeschlagenen API-Aufrufen auftreten. Die Client-SDKs erledigen dies bereits für Sie. Die Postman-Sammlung wird eher als Lerntool bereitgestellt, und sie soll Ihnen zeigen, was die Client-SDKs während Ihrer Entwicklung mit den verschiedenen Client-SDKs tatsächlich tun.
  - question: Wo kann ich Media Services-Beispiele finden?
    answer: >
      Eine Liste mit Beispielen finden Sie im Artikel [Media Services v3: Beispiele](samples-overview.md).
  - question: Wie funktioniert das Paging für große Resultsets (d. h. das Auflisten von Ressourcen) in der API?
    answer: >
      Bei Verwendung der Paginierung sollten Sie immer den Link „Weiter“ verwenden, um die Sammlung zu durchlaufen, und nicht auf eine bestimmte Seitengröße zurückgreifen. Weitere Informationen und Beispiele finden Sie unter [Filterung, Sortierung, Paginierung](filter-order-page-entities-how-to.md).
- name: Konten
  questions:
  - question: Wie verwende ich eine verwaltete Identität, um Daten für Media Services zu verschlüsseln?
    answer: "Werfen Sie einen Blick auf das Tutorial zum [Verwenden eines Key Vault-Schlüssels zur Verschlüsselung von Daten in einem Media Services-Konto](security-encrypt-data-managed-identity-cli-tutorial.md) zur Verwendung der CLI zum Koppeln von Media Services mit Key Vault, um Ihre Daten zu verschlüsseln.  \n"
  - question: Wie verwende ich eine verwaltete Identität, um Media Services Zugriff auf ein eingeschränktes Speicherkonto zu erteilen?
    answer: >
      Wenn Sie auf ein Speicherkonto zugreifen möchten und das Speicherkonto so konfiguriert ist, dass Anforderungen von unbekannten IP-Adressen blockiert werden, führen Sie die Schritte unter [Zugreifen auf Speicher mit einer verwalteten Media Services-Identität](security-access-storage-managed-identity-cli-tutorial.md) aus.
  - question: Wie wird ein Media Services-Konto zwischen Abonnements verschoben?
    answer: >
      Informationen dazu finden Sie unter [Verschieben eines Media Services-Kontos zwischen Abonnements](account-move-account-how-to.md).
- name: Sicherheit
  questions:
  - question: Welche Azure-Rollen können Aktionen mit den Ressourcen von Azure Media Services durchführen?
    answer: >
      Weitere Informationen finden Sie unter [Rollenbasierte Zugriffssteuerung (RBAC) in Azure für Media Services-Konten](security-rbac-concept.md).
- name: Ressourcen, Hochladen und Speicher
  questions:
  - question: Was ist ein Media Services-Medienobjekt?
    answer: >
      Ein Media Services-Medienobjekt ist ein Azure Storage-Kontocontainer, der für jede hochgeladene Videodatei verwendet wird.  Sie verfügt über einen eindeutigen Bezeichner, der mit Transformationen und anderen Vorgängen verwendet wird.  Weitere Informationen finden Sie unter [Medienobjekte in Media Services v3](assets-concept.md).
  - question: Wie erstelle ich ein Media Services-Medienobjekt?
    answer: >
      Jedes Mal, wenn Sie eine Mediendatei hochladen und Vorgänge damit durchführen möchten, z. B. Codierung oder Streaming, erstellen Sie ein Medienobjekt, um die Mediendatei und andere mit dieser Mediendatei verbundene Dateien zu speichern. Medienobjekte werden automatisch für Sie erstellt, wenn Sie das Azure-Portal verwenden. Wenn Sie das Portal nicht zum Hochladen von Dateien verwenden, müssen Sie zuerst ein Medienobjekt erstellen.  Informationen zum Erstellen eines Medienobjekts finden Sie unter [Erstellen eines Medienobjekts](asset-create-asset-how-to.md).
- name: Codierung
  questions:
  - question: Welche Codierungsformate sind für Media Services verfügbar?
    answer: >
      Die gängigen Codierungsformate sind mit Media Services Standard Encoder verfügbar. Eine Liste aller Formate finden Sie unter [Media Encoder Standard-Formate und -Codecs](encode-media-encoder-standard-formats-reference.md).
  - question: Wie erstelle ich einen Media Services-Auftrag?
    answer: >
      Sie können einen Auftrag im Azure-Portal mit der [CLI](job-create-cli-how-to.md), mit REST oder einem der SDKs erstellen. Informationen zur bevorzugten Sprache finden Sie unter [Media Services: Beispiele](https://github.com/Azure-Samples?q=media-services&type=&language=&sort=).
  - question: Kann ich mit Media Services eine automatisch generierte Reihe von Bitraten erstellen?
    answer: >
      Ja.  Weitere Informationen finden Sie auf der Seite [Codieren mit einer automatisch generierten Reihe von Bitraten-/Auflösungspaaren](./encode-autogen-bitrate-ladder.md).
  - question: Unterstützt Media Services die inhaltsbezogene Codierung?
    answer: >
      Ja. Media Services kann ein Video in zwei Durchläufen analysieren und die besten empfohlenen adaptiven Bitraten, Auflösungen und Codierungseinstellungen basierend auf dem Inhalt des bereitgestellten Videos ausgeben. Weitere Informationen finden Sie unter [Voreinstellung für die inhaltsbezogene Codierung](./encode-content-aware-how-to.md).
  - question: Kann ich eine extern codierte oder vorhandene MP4-Datei in Media Services verwenden?
    answer: >
      Ja, im Abschnitt „Streaming“ unter der Frage „Kann ich vorhandene MP4-Dateien streamen“ finden Sie Details und Links zu einer Beispielanwendung, die zeigt, wie eine vorcodierte Single-Bitrate-MP4-Datei hochgeladen wird und das Servermanifest (.ism) und das Clientmanifest (.ismc) generiert werden.

      Beachten Sie die Auswirkungen auf die Leistung des Ursprungs, die in dieser Frage/Antwort ebenfalls genannt werden.
  - question: Kann Media Services für die Codierung von Dateiinhalten in sehr kurzer Form verwendet werden?
    answer: "Kurze Antwort: wird nicht empfohlen.  Sehr kurze Inhalte mit einer Dauer von unter ein oder zwei Minuten eignen sich nicht wirklich für das Streaming mit adaptiven Bitraten.  Wenn Sie Dateien in sehr kurzer Form streamen möchten, wird empfohlen, den Inhalt vorab in ein Format zu codieren, das problemlos mit einer Einzelbitrate gestreamt werden kann. \n\nDa die meisten Player mit adaptiver Bitrate Zeit zum Puffern mehrere Videosegmente benötigen, sowie Zeit zur Analyse der Netzwerkbandbreite vor dem nach oben oder unten „Verschieben“ in der Reihe adaptiver Bitraten benötigen, ist es oft nicht sinnvoll, viele Bitraten für Inhalt bereitzustellen, der unter 30 Sekunden lang ist.  Wenn der Player seinen heuristischen Algorithmus für die richtige Bitrate für die Wiedergabe aufgrund von Netzwerkbedingungen sperrt, wird die Datei gestreamt.  \n\nDarüber hinaus puffern einige Player standardmäßig bis zu drei „Segmente“ des Videos.  Jedes Segment kann zwei bis sechs Sekunden lang sein.  Bei Videos in sehr kurzem Format wird der Player wahrscheinlich puffern und mit der Wiedergabe der ersten ausgewählten Bitrate des ABR-Satzes beginnen. Aus diesem Grund wird empfohlen, eine Single-Bitrate-MP4-Datei zu verwenden und sie in ein Medienobjekt hochzuladen, wenn für Sie die HLS- oder DASH-Manifestgenerierung erforderlich ist. Einzelheiten zur Umsetzung finden Sie unter den obigen Fragen „Kann ich vorhandene MP4-Dateien streamen...“. \n\nDie Dateien müssen nur im HLS- oder DASH-Format übermittelt werden, wenn Sie von den Funktionen dieser Protokolle profitieren möchten.  Für Single-Bitrate-Streams können sie dennoch viel bieten – z. B. schnellere Suche, DRM-Unterstützung, schwierigerer Download über eine URL (aber immer noch möglich!) als ein progressiver MP4-Download im Blobspeicher. Die Unterstützung von Untertiteln für VTT und IMSC1 ist ebenfalls ein weiterer Vorteil.  Darüber hinaus ist die Möglichkeit, zusätzliche Audiowiedergaben oder Synchronisierungen in alternativen Sprachen spät zu binden, in einigen Situationen sehr wertvoll. \n"
- name: Livestreaming
  questions:
  - question: Was ist ein Media Services-Liveereignis?
    answer: >
      Ein Media Services-Liveereignis ist der Prozess der Erfassung von Livevideofeeds und deren Übertragung über ein RTMPS-Protokoll oder über Smooth Streaming. Weitere Informationen zu Media Services-Liveereignissen finden Sie unter [Liveereignisse und Liveausgabe in Media Services](live-event-outputs-concept.md).
  - question: Wie erstelle ich ein Media Services-Liveereignis?
    answer: >
      Der erste Schritt ist die Auswahl eines lokalen Encoders.  Wir haben Beispiele zum Erstellen eines Liveereignisses mit [Wirecast](live-event-wirecast-quickstart.md) und [OBS](live-event-obs-quickstart.md) bereitgestellt. Wenn Sie lieber mit einer Übersicht über Media Services-Liveereignisse beginnen möchten, finden Sie weitere Informationen unter [Liveereignistypen](stream-live-streaming-concept.md#live-event-types).
  - question: Wie führe ich eine Livetranskription mit einem Media Services-Liveereignis durch?
    answer: >
      Azure Media Service übermittelt Video, Audio und Text in unterschiedlichen Protokollen. Wenn Sie Ihren Livestream mittels MPEG-DASH oder HLS/CMAF veröffentlichen, stellt unser Dienst neben den Video- und Audiospuren auch den transkribierten Text im IMSC1.1-kompatiblen TTML-Format bereit. Weitere Informationen zur Livetranskription finden Sie unter [Livetranskription](live-event-live-transcription-how-to.md).
  - question: Wie kann ich die Integrität meines Liveereignisses überwachen?
    answer: >
      Sie können Liveereignisse überwachen, indem Sie Event Grid-Ereignisse abonnieren. Weitere Informationen finden Sie unter [Event Grid-Ereignisschema](monitoring/media-services-event-schemas.md#live-event-types).

      Sie haben folgende Möglichkeiten:

      * [Abonnieren](monitoring/reacting-to-media-services-events.md) Sie die Ereignisse für [Microsoft.Media.LiveEventEncoderDisconnected](monitoring/media-services-event-schemas.md#liveeventencoderdisconnected) auf Streamebene, und überwachen Sie, ob für einen bestimmten Zeitraum neue Verbindungen eingehen, um Ihr Liveereignis zu beenden und zu löschen.

      * [Abonnieren](monitoring/reacting-to-media-services-events.md) Sie die [Taktereignisse](monitoring/media-services-event-schemas.md#liveeventingestheartbeat) auf Spurebene. Wenn die eingehende Bitrate bei allen Spuren auf 0 fällt oder wenn der letzte Zeitstempel nicht mehr ansteigt, können Sie das Liveereignis sicher beenden. Die Taktereignisse gehen alle 20 Sekunden für jede Spur ein, sodass die Informationsmenge etwas höher ausfallen könnte.
- name: Verpackung und Bereitstellung
  questions:
  - question: Ich habe ein Video hochgeladen, codiert und veröffentlicht. Warum wird das Video nicht abgespielt, wenn ich versuche, es zu streamen?
    answer: >
      Einer der häufigsten Gründe ist, dass der Streamingendpunkt, von dem Sie die Wiedergabe ausführen möchten, nicht den Status „Wird ausgeführt“ aufweist.
  - question: Was ist ein Media Services-Streamingendpunkt?
    answer: >
      In Media Services stellt ein Streamingendpunkt einen dynamischen (Just-In-Time-)Paketerstellungs- und Ursprungsdienst dar, der Ihre Live- und On-Demand-Inhalte direkt in einer Clientplayer-App bereitstellen kann und dabei eines der allgemeinen Streamingmedienprotokolle (HLS oder DASH) verwendet. Zudem sorgt der Streamingendpunkt für eine dynamische (Just-In-Time-)Verschlüsselung zu branchenführenden DRMs.  Weitere Informationen zu Streamingendpunkten finden Sie unter [Streamingendpunkte (Ursprung) in Azure Media Services](stream-streaming-endpoint-concept.md)
  - question: Was ist ein Media Services-Streaminglocator?
    answer: >
      Um Videos für die Wiedergabe durch Clients verfügbar zu machen, erstellen Sie einen Streaminglocator und dann die Streaming-URLs. Der Streaminglocator wird auch verwendet, um Streamingrichtlinien anzuwenden, die Regeln für die Verwendung der Mediendateien enthalten.
  - question: Wie erstelle ich einen Media Services-Streaminglocator?
    answer: >
      Um eine Streaming-URL zu erstellen, erstellen Sie zunächst einen Streaminglocator. Sie müssen dann den Hostnamen des Streamingendpunkts und den Pfad des Streaminglocators miteinander verketten.  Weitere Informationen finden Sie unter [Erstellen eines Streaminglocators und von URLs](create-streaming-locator-build-url.md).
  - question: Was ist eine Streamingrichtlinie?
    answer: >
      Mithilfe von Streamingrichtlinien können Sie Streamingprotokolle und Verschlüsselungsoptionen für Ihren Streaminglocator definieren. Media Services v3 bietet einige vordefinierte Streamingrichtlinien. Weitere Informationen finden Sie unter [Streamingrichtlinien](./stream-streaming-policy-concept.md).
  - question: Wie erstelle ich eine Media Services-Streamingrichtlinie?
    answer: >
      Eine Liste der vordefinierten Richtlinien, die Sie für die ersten Schritte verwenden können, finden Sie unter [Streamingrichtlinien](./stream-streaming-policy-concept.md).
  - question: Wie kann ich Inhalte im HLS-Format auf Apple-Geräte streamen?
    answer: >
      Stellen Sie sicher, dass Sie am Ende Ihres Pfads (nach dem Bereich **/manifest** der URL) **(format=m3u8-cmaf)** verwenden, um den Ursprungsserver des Streamings anzuweisen, HLS-Inhalte (HTTP Live Streaming) für die Nutzung auf nativen Apple iOS-Geräten zurückzugeben. Ausführliche Informationen finden Sie unter [Bereitstellung von Inhalten](encode-dynamic-packaging-concept.md).
  - question: Kann ich vorhandene MP4-Dateien streamen, die in einer anderen Lösung vorcodiert oder codiert sind?
    answer: "Ja, der Media Services-Ursprungsserver (Streamingendpunkt) unterstützt die dynamische Paketerstellung von MP4-Dateien in das HLS- oder DASH-Streamingformat. Der Inhalt muss jedoch im Closed-GOP-Format (geschlossene Bildgruppe) codiert werden, mit kurzen GOPs mit einer Dauer von 2 bis 6 Sekunden. Es werden die folgenden Einstellungen empfohlen: 2-Sekunden-GOPs, Keyframeabstand von min. und max. 2 Sekunden, Codieren mit konstanter Bitrate (CBR-Modus). Die meisten Inhalte in diesem Format, die mit dem H264- oder HEVC-Videocodec zusammen mit dem AAC-Audioformat codiert werden, können unterstützt werden. Es können auch zusätzliche Audioformate unterstützt werden, die vorcodiert sind, z. B. Dolby DD+. \n\nUm dies zu erreichen, erstellen Sie ein Medienobjekt, laden Sie die vorcodierten Medienobjekte mithilfe von Blob-Storage-Client-SDKs in den Container des Medienobjekts hoch, und generieren Sie dann die erforderlichen Servermanifest- (.ism) und Clientmanifestdateien. Im folgenden .NET-Beispiele-Projekt wird ein Beispiel bereitgestellt, das die Vorgehensweise dazu zeigt.  \nEinzelheiten finden Sie im Beispielprojekt – [Stream existing MP4 files](https://github.com/Azure-Samples/media-services-v3-dotnet/tree/main/Streaming/StreamExistingMp4) (Streamen vorhandener MP4-Dateien)\n\nBeachten Sie, dass dieser Ansatz Auswirkungen auf die Leistung hat, da der integrierte Encoder in Azure Media Services auch binäre Indizes (MPI-Dateien) generiert, die die Zugriffszeit auf die MP4-Dateien verbessern.  Ohne diese Dateien kann der Server etwas mehr CPU bei hoher Auslastung verwenden, z. B. beim Streamen einer vorhandenen Single-Bitrate-MP4-Datei mit HLS oder Dash](https://github.com/Azure-Samples/media-services-v3-dotnet/tree/main/Streaming/StreamExistingMp4) Sie sollten die CPU-Auslastung des Streamingendpunkts in Azure Monitor überwachen, wenn Sie mit diesem Ansatz hochskalieren.  Wenn Sie planen, mit einer großen Bibliothek von MP4-Dateien, die außerhalb von Azure Media Services vorcodiert sind, in die Produktion zu gehen, öffnen Sie ein Supportticket, um Ihre Architektur überprüfen zu lassen und nach Möglichkeiten zu suchen, die Leistung des Ursprungsservers von vorcodierten MP4-Inhalten zu verbessern. \n"
- name: Inhaltsschutz
  questions:
  - question: Wie kann ich meine Medieninhalte mit dynamischer Verschlüsselung bereitstellen?
    answer: >
      Die dynamische Verschlüsselung schützt Ihre Medien ab dem Zeitpunkt, an dem sie Ihren Computer verlassen, während des gesamten Prozesses der Speicherung, Verarbeitung und Übermittlung. Mit Media Services können Sie Ihre zu übermittelnden Live- und On-Demand-Inhalte dynamisch mit Advanced Encryption Standard (AES-128) oder einem der drei wichtigsten DRM-Systeme verschlüsseln: Microsoft PlayReady, Google Widevine und Apple FairPlay. Weitere Informationen finden Sie unter [Schützen Sie Ihren Inhalt mit der dynamischen Verschlüsselung von Media Services](./drm-content-protection-concept.md).
  - question: Sollte ich eine Verschlüsselung mit unverschlüsseltem AES-128-Schlüssel oder ein DRM-System verwenden?
    answer: >
      Kunden fragen sich oft, ob sie die AES-Verschlüsselung oder ein DRM-System verwenden sollten. Der Hauptunterschied zwischen den beiden Systemen besteht darin, dass bei der AES-Verschlüsselung der Inhaltsschlüssel über TLS an den Client übertragen wird, sodass er bei der Übertragung verschlüsselt ist, aber keine zusätzliche Verschlüsselung aufweist (Klartext). So kann der Schlüssel zur Entschlüsselung des Inhalts für den Clientplayer zugänglich gemacht und in einer Netzwerkablaufverfolgung auf dem Client als unverschlüsselter Text angezeigt werden. Die Verschlüsselung mit einem unverschlüsselten AES-128-Schlüssel eignet sich für Anwendungsfälle, in denen der Betrachter vertrauenswürdig ist (z.B. bei Unternehmensvideos, die innerhalb eines Unternehmens verteilt und von Mitarbeitern angesehen werden).


      DRM-Systeme wie PlayReady, Widevine und FairPlay bieten eine zusätzliche Verschlüsselungsebene für den Schlüssel, der zum Entschlüsseln des Inhalts verwendet wird (im Vergleich zu einem unverschlüsselten AES-128-Schlüssel). Der Inhaltsschlüssel wird zusätzlich zur Verschlüsselung auf Übertragungsebene durch TLS mit einem durch die DRM-Runtime geschützten Schlüssel verschlüsselt. Zusätzlich erfolgt die Entschlüsselung in einer sicheren Umgebung auf Betriebssystemebene, wo ein Angriff durch einen böswilligen Benutzer schwieriger auszuführen ist. DRM wird für Anwendungsfälle empfohlen, in denen der Betrachter möglicherweise nicht vertrauenswürdig ist und Sie ein Höchstmaß an Sicherheit benötigen.
  - question: Wie zeige ich ein Video nur für Benutzer mit bestimmten Berechtigungen an, ohne Azure AD zu verwenden?
    answer: >
      Sie müssen keinen bestimmten Tokenanbieter wie Azure Active Directory (Azure AD) verwenden. Sie können einen eigenen [JWT](https://docs.microsoft.com/azure/active-directory/develop/security-tokens#json-web-tokens-and-claims)-Anbieter (einen sogenannten Sicherheitstokendienst oder STS) erstellen und dabei eine Verschlüsselung mit asymmetrischem Schlüssel verwenden. Sie können in Ihrem benutzerdefinierten Sicherheitstokendienst Ansprüche basierend auf Ihrer Geschäftslogik hinzufügen.


      Stellen Sie sicher, dass der Aussteller, die Zielgruppe und die Ansprüche genau dem Inhalt des JWT und dem Wert `ContentKeyPolicyRestriction` in `ContentKeyPolicy` entsprechen.


      Weitere Informationen finden Sie unter [Inhaltsschutz mit der dynamischen Verschlüsselung von Media Services](drm-content-protection-concept.md).
  - question: Wie und wo kann ich JWT-Token abrufen, um damit dann eine Lizenz oder einen Schlüssel anzufordern?
    answer: >
      Für die Produktion benötigen Sie einen Sicherheitstokendienst (Webdienst), der bei einer HTTPS-Anforderung ein JWT-Token ausgibt. Zum Testen können Sie den in der `GetTokenAsync`-Methode angegebenen Code verwenden, der in [Program.cs](https://github.com/Azure-Samples/media-services-v3-dotnet-tutorials/blob/main/AMSV3Tutorials/EncryptWithDRM/Program.cs) definiert ist.


      Der Player fordert nach der Authentifizierung eines Benutzers beim STS ein solches Token an und weist dieses als Wert des Tokens zu. Sie können die [Azure Media Player-API](https://amp.azure.net/libs/amp/latest/docs/) verwenden.


      Ein Beispiel für die Ausführung des STS mit einem symmetrischen oder einem asymmetrischen Schlüssel finden Sie im [JWT-Tool](https://aka.ms/jwt). Ein Beispiel für einen Player, der auf Azure Media Player basiert und ein solches JWT-Token verwendet, finden Sie im [Azure-Medientesttool](https://aka.ms/amtest). (Erweitern Sie den Link **player_settings**, um die Tokeneingabe anzuzeigen.)
  - question: Wie autorisiere ich Anforderungen zum Streamen von Videos mit AES-Verschlüsselung?
    answer: >
      Der richtige Ansatz ist die Nutzung von eines Sicherheitstokendiensts. Fügen Sie im STS je nach Benutzerprofil unterschiedliche Ansprüche hinzu (z. B. „Premium-Benutzer“, „Basic-Benutzer“, „Benutzer der kostenlosen Testversion“). Bei unterschiedlichen Ansprüchen in einem JWT kann der Benutzer unterschiedliche Inhalte sehen. Für andere Inhalte oder Medienobjekte weist `ContentKeyPolicyRestriction` den entsprechenden Wert für `RequiredClaims` auf.


      Verwenden Sie die Azure Media Services-APIs für die Konfiguration von Lizenzen/Schlüsselbereitstellungen und die Verschlüsselung Ihrer Objekte (siehe [dieses Beispiel](https://github.com/Azure-Samples/media-services-v3-dotnet-tutorials/blob/main/AMSV3Tutorials/EncryptWithAES/Program.cs)).


      Weitere Informationen finden Sie unter


      - [Übersicht über den Inhaltsschutz](drm-content-protection-concept.md)

      - [Entwurf eines Multi-DRM-Inhaltsschutzsystems mit Zugriffssteuerung](architecture-design-multi-drm-system.md)
  - question: Warum wird nur Audio, aber kein Video wiedergegeben, wenn ich den FairPlay-Offlinemodus verwende?
    answer: "Dieses Verhalten scheint durch den Entwurf der Beispielanwendung bedingt zu sein. Wenn ein alternativer Audiotitel vorhanden ist (was bei HLS der Fall ist), werden sowohl iOS 10 als auch iOS 11 im Offlinemodus standardmäßig den alternativen Audiotitel verwenden. Um dieses Verhalten für den FPS-Offlinemodus zu kompensieren, entfernen Sie den alternativen Audiotitel aus dem Datenstrom. Um dies für Media Services zu erreichen, fügen Sie den dynamischen Manifestfilter **audio-only=false** hinzu. Eine HLS-URL endet somit mit **.ism/manifest(format=m3u8-aapl,audio-only=false)** . \n"
  - question: Warum gibt FairPlay offline nur Audiodaten ohne Videomodus wieder, wenn ich „audio-only=false“ hinzufüge?
    answer: >
      Je nach Cacheschlüsseldesign für das Content Delivery Network wird der Inhalt möglicherweise zwischengespeichert. Löschen Sie den Cacheinhalt.
  - question: Wie sieht die Struktur der heruntergeladenen bzw. Offlinedateien auf iOS-Geräten aus?
    answer: "Die heruntergeladene Dateistruktur auf einem iOS-Gerät sieht aus wie auf dem folgenden Screenshot. Der Ordner `_keys` speichert heruntergeladene FPS-Lizenzen, wobei eine Speicherdatei für jeden Lizenzdiensthost verwendet wird. Der Ordner `.movpkg` speichert Audio- und Videoinhalte. \n\nDer erste Ordner mit einem Namen, der mit einem Bindestrich gefolgt von einer Zahl endet, weist Videoinhalte auf. Der numerische Wert ist die Spitzenbandbreite der Videowiedergabe. Der zweite Ordner mit einem Namen, der mit einem Bindestrich endet, auf den „0“ folgt, enthält Audioinhalte. Der dritte Ordner namens `Data` enthält die Masterwiedergabeliste des FPS-Inhalts. Schließlich enthält „boot.xml“ eine vollständige Beschreibung des Inhalts des Ordners `.movpkg`. \n\n![Offlinedateistruktur der iOS-Beispielanwendung für FairPlay](media/drm-offline-fairplay-for-ios-concept/offline-fairplay-file-structure.png)\n\nBeispiel für die Datei „boot.xml“:\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<HLSMoviePackage xmlns:xsi=\"https://www.w3.org/2001/XMLSchema-instance\" xmlns=\"http://apple.com/IMG/Schemas/HLSMoviePackage\" xsi:schemaLocation=\"http://apple.com/IMG/Schemas/HLSMoviePackage /System/Library/Schemas/HLSMoviePackage.xsd\">\n  <Version>1.0</Version>\n  <HLSMoviePackageType>PersistedStore</HLSMoviePackageType>\n  <Streams>\n    <Stream ID=\"1-4DTFY3A3VDRCNZ53YZ3RJ2NPG2AJHNBD-0\" Path=\"1-4DTFY3A3VDRCNZ53YZ3RJ2NPG2AJHNBD-0\" NetworkURL=\"https://willzhanmswest.streaming.mediaservices.windows.net/e7c76dbb-8e38-44b3-be8c-5c78890c4bb4/MicrosoftElite01.ism/QualityLevels(127000)/Manifest(aac_eng_2_127,format=m3u8-aapl)\">\n      <Complete>YES</Complete>\n    </Stream>\n    <Stream ID=\"0-HC6H5GWC5IU62P4VHE7NWNGO2SZGPKUJ-310656\" Path=\"0-HC6H5GWC5IU62P4VHE7NWNGO2SZGPKUJ-310656\" NetworkURL=\"https://willzhanmswest.streaming.mediaservices.windows.net/e7c76dbb-8e38-44b3-be8c-5c78890c4bb4/MicrosoftElite01.ism/QualityLevels(161000)/Manifest(video,format=m3u8-aapl)\">\n      <Complete>YES</Complete>\n    </Stream>\n  </Streams>\n  <MasterPlaylist>\n    <NetworkURL>https://willzhanmswest.streaming.mediaservices.windows.net/e7c76dbb-8e38-44b3-be8c-5c78890c4bb4/MicrosoftElite01.ism/manifest(format=m3u8-aapl,audio-only=false)</NetworkURL>\n  </MasterPlaylist>\n  <DataItems Directory=\"Data\">\n    <DataItem>\n      <ID>CB50F631-8227-477A-BCEC-365BBF12BCC0</ID>\n      <Category>Playlist</Category>\n      <Name>master.m3u8</Name>\n      <DataPath>Playlist-master.m3u8-CB50F631-8227-477A-BCEC-365BBF12BCC0.data</DataPath>\n      <Role>Master</Role>\n    </DataItem>\n  </DataItems>\n</HLSMoviePackage>\n```\n"
  - question: Wie kann ich für einige Clients/Benutzer persistente (offlinefähige) Lizenzen und für andere nicht persistente (nicht offlinefähige) Lizenzen übermitteln? Muss ich den Inhalt duplizieren und separate symmetrische Schlüssel verwenden?
    answer: >
      Da Media Services v3 ein Medienobjekt mit mehreren `StreamingLocator`-Instanzen zulässt, können folgende Elemente zur gleichen Zeit vorhanden sein:


      * Eine `ContentKeyPolicy`-Instanz mit `license_type = "persistent"` und `ContentKeyPolicyRestriction` mit Anspruch auf `"persistent"` und der zugehörige `StreamingLocator`.

      * Eine weitere `ContentKeyPolicy`-Instanz mit `license_type="nonpersistent"` und `ContentKeyPolicyRestriction` mit Anspruch auf `"nonpersistent` und der zugehörige `StreamingLocator`.

      * Zwei `StreamingLocator`-Instanzen mit unterschiedlichen `ContentKey`-Werten.


      Abhängig von der Geschäftslogik des benutzerdefinierten STS werden unterschiedliche Ansprüche im JWT-Token ausgegeben. Mit dem Token kann nur die dazugehörige Lizenz abgerufen und nur die entsprechende URL wiedergegeben werden.
  - question: Wie sieht die Zuordnung zwischen den Sicherheitsstufen von "Widevine" und "Media Services DRM" aus?
    answer: "In der Widevine DRM-Architekturübersicht von Google sind drei verschiedene Sicherheitsstufen definiert. In der [Azure Media Services-Dokumentation zur Widevine-Lizenzvorlage](drm-widevine-license-template-concept.md) werden jedoch fünf Sicherheitsstufen (Clientstabilitätsanforderungen für die Wiedergabe) beschrieben. In diesem Abschnitt wird die Zuordnung der Sicherheitsstufen erläutert.\n\nBeide Gruppen von Sicherheitsstufen werden durch Google Widevine definiert. Der Unterschied besteht in der Nutzungsebene: Architektur oder API. Die fünf Sicherheitsstufen werden in der Widevine-API verwendet. Das `content_key_specs`-Objekt, das `security_level` enthält, wird deserialisiert und durch den Widevine-Lizenzdienst von Azure Media Services an den globalen Widevine-Übermittlungsdienst übergeben. Die folgende Tabelle zeigt die Zuordnung zwischen den beiden Gruppen von Sicherheitsstufen.\n\n| **In der Widevine-Architektur definierte Sicherheitsstufen** |**In der Widevine-API verwendete Sicherheitsstufen**|\n|---|---| \n| **Sicherheitsstufe 1**: Die gesamte Inhaltsverarbeitung, Kryptografie und Kontrolle findet innerhalb der vertrauenswürdigen Ausführungsumgebung (Trusted Execution Environment, TEE) statt. In einigen Implementierungsmodellen findet die Sicherheitsverarbeitung unter Umständen in unterschiedlichen Chips statt.|**security_level=5**: Kryptografie, Decodierung und Verarbeitung von Medien (komprimiert und unkomprimiert) müssen innerhalb einer hardwaregestützten TEE stattfinden.<br/><br/>**security_level=4**: Kryptografie und Decodierung müssen innerhalb einer hardwaregestützten TEE durchgeführt werden.|\n**Sicherheitsstufe 2**: Die Kryptografie (aber nicht die Videoverarbeitung) wird innerhalb der TEE durchgeführt. Entschlüsselte Puffer werden an die Anwendungsdomäne zurückgegeben und über separate Videohardware oder -software verarbeitet. Auf der zweiten Stufe werden Kryptografieinformationen allerdings weiterhin nur innerhalb der TEE verarbeitet.| **security_level=3**: Die zentralen Vorgänge für Daten und Verschlüsselung müssen innerhalb einer hardwaregestützten TEE ausgeführt werden. |\n| **Sicherheitsstufe 3**: Es gibt keine TEE auf dem Gerät. Zum Schutz der kryptografischen Informationen und entschlüsselten Inhalte können geeignete Maßnahmen unter dem Hostbetriebssystem ergriffen werden. Eine Implementierung der dritten Stufe kann auch ein hardwarebasiertes Kryptografiemodul enthalten. Dadurch wird aber nur die Leistung verbessert, nicht die Sicherheit. | **security_level=2**: Erfordert Softwareverschlüsselung und einen verborgenen Decoder.<br/><br/>**security_level=1**: Erfordert softwarebasierte White-Box-Verschlüsselung.|\n"
- name: Überwachung
  questions:
  - question: Wie überwache ich meine Media Services-Ressourcen?
    answer: >
      Verwenden Sie Azure Monitor, um nachzuverfolgen, was mit Ihren Media Services-Ressourcen geschieht.  Weitere Informationen finden Sie unter [Überwachen von Media Services](./monitoring/monitor-media-services.md). Schrittanleitungen umfassen [Überwachen von Media Services-Metriken](./monitoring/media-services-metrics-howto.md) und [Überwachen von Media Services-Diagnoseprotokolle](./monitoring/media-services-diagnostic-logs-howto.md).
  - question: Wie überwache ich mein Media Services-Liveereignis?
    answer: >
      Verwenden Sie [Azure Event Grid](./monitoring/reacting-to-media-services-events.md), um Ihr Liveereignis ohne einen Abrufdienst zu überwachen. Schrittanleitungen umfassen [Erstellen und Überwachen von Media Services-Ereignissen mit Event Grid mithilfe des Azure-Portal](./monitoring/monitor-events-portal-how-to.md) und [Erstellen und Überwachen von Media Services-Ereignissen mit Event Grid mithilfe der Azure CLI](./monitoring/job-state-events-cli-how-to.md).
- name: Player
  questions:
  - question: Welche Videoplayer kann ich mit Media Services verwenden?
    answer: >
      Media Services funktioniert mit Azure Media Player, Shaka und Video.js. Weitere Informationen finden Sie in der [Azure Media Player-Dokumentation](../azure-media-player/azure-media-player-overview.md) unter [Verwenden des Shaka-Players mit Azure Media Services](./player-shaka-player-how-to.md) oder [Verwenden des Video.js-Players mit Azure Media Services](./player-media-players-concept.md).
- name: Hochverfügbarkeit
  questions:
  - question: Unterstützt Media Services Hochverfügbarkeit?
    answer: >
      Weitere Informationen zu Media Services und Hochverfügbarkeit finden sich unter [Hochverfügbarkeit bei Media Services und Video on Demand (VoD)](./architecture-high-availability-encoding-concept.md).
- name: Migrieren aus v2
  questions:
  - question: Wie kann ich von Media Services v2 zu Media Services v3 migrieren?
    answer: >
      Wir haben einen [umfassenden Leitfaden für die Migration von v2 zu v3](./migrate-v-2-v-3-migration-introduction.md) erstellt.  Wir sind sehr daran interessiert, mehr über Ihre Migrationserfahrung und Ihre Anforderungen zu erfahren. Senden Sie uns daher gerne Ihr Feedback über ein GitHub-Problem oder Supportticket.
- name: Problembehandlung
  questions:
  - question: Wie kann ich herausfinden, was dieser Fehlercode bedeutet?
    answer: >
      Wir haben Fehlercodes in den folgenden Referenzen dokumentiert: [Fehlercodes für Streamingendpunkte](./stream-streaming-endpoint-error-codes-reference.md), [Fehlercodes für Liveereignisse](./live-event-error-codes-reference.md), [Fehlercodes für Aufträge](./job-error-codes-reference.md).  Wenn Sie dort keine Antworten finden, erstellen Sie ein Supportticket.
  - question: Wie kann ich meine Anmeldeinformationen zurücksetzen?
    answer: >
      Sie können [Ihre Kontoanmeldeinformationen mit der CLI zurücksetzen](./account-reset-account-credentials.md).
- name: Abrechnung und Kostenschätzungen
  questions:
  - question: Wie viel kostet Media Services?
    answer: >
      Weitere Informationen finden Sie unter den [Preisinformationen zu Media Services](https://azure.microsoft.com/pricing/details/media-services/).
- name: Kontingente und Einschränkungen
  questions:
  - question: Welche Kontingente und Grenzwerte gelten für Media Services?
    answer: >
      Weitere Informationen finden Sie unter [Media Services: Kontingente und Grenzwerte](limits-quotas-constraints-reference.md).
- name: Compliance und Kundendaten
  questions:
  - question: Speichert Media Services irgendwelche Kundendaten außerhalb der Dienstregion?
    answer: >
      - Kunden fügen ihrem Azure Media Services-Konto ihre eigenen Speicherkonten an.  Alle Medienobjektdaten werden in diesen zugeordneten Speicherkonten gespeichert, und der Kunde steuert den Standort und den Replikationstyp dieses Speichers.

      - Zusätzliche Daten, die dem Media Services Konto zugeordnet sind (einschließlich Inhaltsverschlüsselungsschlüssel, Tokenüberprüfungsschlüssel, JobInputHttp-URLs und andere Entitätsmetadaten), werden in Microsoft-eigenem Speicher innerhalb der Region gespeichert, die für das Media Services-Konto ausgewählt ist.
        - Aufgrund der [Anforderungen an die Datenresidenz](https://azure.microsoft.com/global-infrastructure/data-residency/#more-information) in den Regionen „Brasilien, Süden“ und „Asien, Südosten“ werden die zusätzlichen Kontodaten auf zonenredundante Weise gespeichert und sind in einer einzigen Region enthalten. Für „Asien, Südosten“ werden alle zusätzlichen Kontodaten in Singapur und für „Brasilien, Süden“ in Brasilien gespeichert.
        - In anderen Regionen als „Brasilien, Süden“ und „Asien, Südosten“ können die zusätzlichen Kontodaten auch in Microsoft-eigenem Speicher im [Regionspaar](../../best-practices-availability-paired-regions.md) gespeichert sein.
      - Azure Media Services ist ein regionaler Dienst und bietet keine [Hochverfügbarkeit](architecture-high-availability-encoding-concept.md) oder Datenreplikation. Kunden, die diese Features benötigen, wird dringend empfohlen, eine Lösung mithilfe von Media Services-Konten in mehreren Regionen zu erstellen.  Ein Beispiel für das Erstellen einer Lösung für hohe Verfügbarkeit mit Video on Demand (VoD) von Media Services ist als Leitfaden verfügbar.
  - question: Bietet Media Services Hochverfügbarkeit oder Datenreplikation?
    answer: '-   Azure Media Services ist ein regionaler Dienst und bietet keine Hochverfügbarkeit oder Datenreplikation. Kunden, die diese Features benötigen, wird dringend empfohlen, eine Lösung mithilfe von Media Services-Konten in mehreren Regionen zu erstellen. Ein Beispiel für das Erstellen einer Lösung für [hohe Verfügbarkeit mit Video on Demand (VoD) von Media Services](./architecture-high-availability-encoding-concept.md) ist als Leitfaden verfügbar.'

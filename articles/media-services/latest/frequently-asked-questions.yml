### YamlMime:FAQ
metadata:
  title: 'Azure Media Services: Häufig gestellte Fragen'
  description: Erhalten Sie Antworten auf häufig gestellte Fragen zu Azure Media Services.
  ms.service: media-services
  ms.custom: contperf-fy21q4
  ms.openlocfilehash: 41b7adb4a56b5ba325b7ed86b974ea58d5a4c57c
  ms.sourcegitcommit: f6e2ea5571e35b9ed3a79a22485eba4d20ae36cc
  ms.translationtype: HT
  ms.contentlocale: de-DE
  ms.lasthandoff: 09/24/2021
  ms.locfileid: "128619028"
title: Häufig gestellte Fragen zu Azure Media Services
summary: Dieser Artikel bietet Antworten auf häufig gestellte Fragen zu Azure Media Services.
sections:
- name: Entwickeln mit SDKs
  questions:
  - question: Wo finde ich die Media Services-API und SDKs?
    answer: >
      Hier sehen Sie eine Auflistung:

      - [OpenAPI-Spezifikation (Swagger)](https://aka.ms/ams-v3-rest-sdk)

      - [Azure-Befehlszeilenschnittstelle](/cli/azure/install-azure-cli)

      - [.NET](https://aka.ms/ams-v3-dotnet-sdk)

      - [Java](https://aka.ms/ams-v3-java-sdk)

      - [Python](https://aka.ms/ams-v3-python-sdk)

      - [Node.js](https://aka.ms/ams-v3-nodejs-sdk)

      - [Go](https://aka.ms/ams-v3-go-sdk)

      - [Ruby](https://aka.ms/ams-v3-ruby-sdk)
  - question: Sollte ich die Client-SDKs verwenden oder direkt in die REST-API schreiben?
    answer: >
      Es empfiehlt sich nicht, die REST-API für Media Services direkt in Ihren eigenen Bibliothekscode einzuschließen. Wollten Sie dies ordnungsgemäß für Produktionszwecke tun, müssten Sie die vollständige Azure Resource Manager-Wiederholungslogik implementieren und verstehen, wie Vorgänge mit langer Ausführungslaufzeit in Resource Manager-APIs verwaltet werden. Die Client-SDKs für verschiedene Sprachen – z. B. .NET, Java, TypeScript, Python und Ruby – übernehmen dies automatisch für Sie, um die Gefahr von Problemen mit Wiederholungslogik oder fehlgeschlagenen API-Aufrufen zu verringern. Die Postman-Sammlung wird eher als Lerntool bereitgestellt, um Ihnen zu zeigen, was die Client-SDKs während Ihrer Entwicklungsarbeit mit ihnen im Netzwerk tun.
  - question: Wo kann ich Media Services-Beispiele finden?
    answer: >
      Eine Liste mit Beispielen finden Sie im Artikel [Media Services v3: Beispiele](samples-overview.md).
  - question: Wie funktioniert die Auslagerung großer Resultsets (etwa einer Liste von Ressourcen) in der API?
    answer: >
      Bei Verwendung der Paginierung sollten Sie immer den Link „Weiter“ verwenden, um die Sammlung zu durchlaufen, und nicht auf eine bestimmte Seitengröße zurückgreifen. Weitere Informationen und Beispiele finden Sie unter [Filtern, Sortieren und Auslagern von Entitäten](filter-order-page-entities-how-to.md).
- name: Konten
  questions:
  - question: Wie verwende ich eine verwaltete Identität, um Daten für Media Services zu verschlüsseln?
    answer: "Informationen zur Verwendung der Azure-Befehlszeilenschnittstelle zum Koppeln von Media Services mit Key Vault, um Ihre Daten zu verschlüsseln, finden Sie im Tutorial zum [Verwenden eines Key Vault-Schlüssels zur Verschlüsselung von Daten in einem Media Services-Konto](security-encrypt-data-managed-identity-cli-tutorial.md).  \n"
  - question: Wie verwende ich eine verwaltete Identität, um Media Services Zugriff auf ein eingeschränktes Speicherkonto zu erteilen?
    answer: >
      Wenn Sie möchten, dass Media Services auf ein Speicherkonto zugreifen kann, und das Speicherkonto so konfiguriert ist, dass Anforderungen von unbekannten IP-Adressen blockiert werden, führen Sie die Schritte unter [Zugreifen auf Speicher mit einer verwalteten Media Services-Identität](security-access-storage-managed-identity-cli-tutorial.md) aus.
  - question: Wie wird ein Media Services-Konto zwischen Abonnements verschoben?
    answer: >
      Lesen Sie dazu [Verschieben eines Media Services-Kontos zwischen Abonnements](account-move-account-how-to.md).
- name: Sicherheit
  questions:
  - question: Welche Azure-Rollen können Aktionen mit den Ressourcen von Media Services durchführen?
    answer: >
      Weitere Informationen finden Sie unter [Rollenbasierte Zugriffssteuerung (RBAC) in Azure für Media Services-Konten](security-rbac-concept.md).
- name: Ressourcen, Hochladen und Speichern
  questions:
  - question: Was ist ein Media Services-Medienobjekt?
    answer: >
      Ein Media Services-Medienobjekt ist ein Azure Storage-Kontocontainer, der für jede hochgeladene Videodatei verwendet wird. Er weist einen eindeutigen Bezeichner auf, der für Transformationen und andere Vorgänge verwendet wird. Lesen Sie dazu [Medienobjekte in Azure Media Services v3](assets-concept.md).
  - question: Wie erstelle ich ein Media Services-Medienobjekt?
    answer: >
      Jedes Mal, wenn Sie eine Mediendatei hochladen und Vorgänge damit durchführen möchten, z. B. Codierung oder Streaming, erstellen Sie ein Medienobjekt, um die Mediendatei und mit ihr verbundene Dateien zu speichern. Medienobjekte werden automatisch für Sie erstellt, wenn Sie das Azure-Portal verwenden. Wenn Sie nicht das Portal zum Hochladen von Dateien verwenden, müssen Sie zuerst ein Medienobjekt erstellen. Weitere Informationen finden Sie unter [Erstellen eines Medienobjekts](asset-create-asset-how-to.md).
- name: Codierung
  questions:
  - question: Welche Codierungsformate sind für Media Services verfügbar?
    answer: >
      Die gängigen Codierungsformate sind mit Media Services Standard Encoder verfügbar. Eine Liste aller Formate finden Sie unter [Media Encoder Standard-Formate und -Codecs](encode-media-encoder-standard-formats-reference.md).
  - question: Wie erstelle ich einen Media Services-Auftrag?
    answer: >
      Sie können einen Auftrag im Azure-Portal mithilfe der [Azure-Befehlszeilenschnittstelle](job-create-cli-how-to.md), REST oder einem der SDKs erstellen. Informationen dazu finden Sie unter [Media Services: Beispiele](https://github.com/Azure-Samples?q=media-services&type=&language=&sort=) für Ihre bevorzugte Sprache.
  - question: Kann ich mit Media Services eine automatisch generierte Reihe von Bitraten erstellen?
    answer: >
      Ja.  Lesen Sie dazu [Codieren mit einer automatisch generierten Reihe von Bitraten-/Auflösungspaaren](./encode-autogen-bitrate-ladder.md).
  - question: Unterstützt Media Services die inhaltsbezogene Codierung?
    answer: >
      Ja. Media Services kann für ein Video eine Analyse in zwei Durchgängen durchführen. Anschließend kann es basierend auf den Inhalten des Videos die besten Einstellungen für adaptive Bitraten, Auflösungen und Codierung empfehlen. Weitere Informationen finden Sie unter [Verwenden der Voreinstellung für die inhaltsbezogene Codierung](./encode-content-aware-how-to.md).
  - question: Kann ich eine extern codierte oder vorhandene MP4-Datei in Media Services verwenden?
    answer: >
      Ja. Ausführliche Informationen und Links zu einer Beispielanwendung, die zeigt, wie Sie eine vorcodierte MP4-Datei mit einheitlicher Bitrate hochladen, und das Servermanifest (ISM) sowie das Clientmanifest (ISMC) generieren, finden Sie in der Antwort auf die Frage „Kann ich vorhandene MP4-Dateien streamen, die in einer anderen Lösung vorcodiert oder codiert sind?“ im Abschnitt über Verpackung und Zustellung. In dieser Antwort sind außerdem die Auswirkungen auf die Leistung der Quelle beschrieben.
  - question: Kann Media Services für die Codierung von sehr kurzen Dateiinhalten verwendet werden?
    answer: "Wir raten davon ab. Sehr kurze Inhalte mit einer Dauer von unter ein oder zwei Minuten eignen sich nicht wirklich für das Streaming mit adaptiven Bitraten. Wenn Sie sehr kurze Dateien streamen möchten, empfiehlt es sich, die Inhalte vorab in einem Format zu codieren, das sich problemlos mit einer einheitlichen Bitrate streamen lässt. \n\nDa die meisten Player mit adaptiver Bitrate Zeit zum Puffern mehrerer Videosegmente sowie Zeit zur Analyse der Netzwerkbandbreite vor dem „Verschieben“ nach oben oder unten in der Reihe adaptiver Bitraten benötigen, ist es oft nicht sinnvoll, viele Bitraten für Inhalte bereitzustellen, die unter 30 Sekunden lang sind. Wenn der Player seinen heuristischen Algorithmus auf Grundlage der Netzwerkbedingungen auf die richtige Bitrate für die Wiedergabe fixiert hat, ist das Streamen der Datei bereits beendet.  \n\nDarüber hinaus puffern einige Player standardmäßig bis zu drei Videosegmente. Jedes Segment kann zwei bis sechs Sekunden lang sein. Bei Videos in sehr kurzem Format ist es wahrscheinlich, dass der Player puffert und die Wiedergabe mit der ersten ausgewählten Bitrate des Satzes der adaptiven Bitraten beginnt. Aus diesem Grund empfiehlt es sich, eine MP4-Datei mit einheitlicher Bitrate zu verwenden und sie in ein Medienobjekt hochzuladen, wenn für Sie die Generierung eine HLS- oder DASH-Manifests erforderlich ist. Ausführliche Informationen dazu, wie dies erreicht werden kann, finden Sie in der Antwort auf die Frage „Kann ich vorhandene MP4-Dateien streamen, die in einer anderen Lösung vorcodiert oder codiert sind?“ im Abschnitt über Verpackung und Zustellung. \n\nDie Dateien müssen nur dann im HLS- oder DASH-Format übermittelt werden, wenn Sie die Funktionen dieser Protokolle nutzen möchten. Für Streams mit einheitlicher Bitrate können sie dennoch viel bieten – z. B. schnellere Suche, DRM-Unterstützung, erschwerter Download über eine URL (der aber immer noch möglich ist!) im Vergleich zum Download einer progressiven MP4 in Blobspeicher. Die Unterstützung von Untertiteln für VTT und IMSC1 ist ein weiterer Vorteil. Darüber hinaus ist die Möglichkeit, zusätzliche Audiowiedergaben oder Synchronisierungen in alternativen Sprachen spät zu binden, in einigen Situationen sehr wertvoll. \n"
- name: Livestreaming
  questions:
  - question: Was ist ein Media Services-Liveereignis?
    answer: >
      Ein Media Services-Liveereignis ist der Prozess der Erfassung von Livevideofeeds und deren Übertragung über ein RTMPS-Protokoll oder über Smooth Streaming. Weitere Informationen finden Sie unter [Liveereignisse und Liveausgaben in Media Services](live-event-outputs-concept.md).
  - question: Wie erstelle ich ein Media Services-Liveereignis?
    answer: >
      Der erste Schritt besteht in der Auswahl eines lokalen Encoders. Wir stellen Beispiele zum Erstellen eines Liveereignisses mit [Wirecast](live-event-wirecast-quickstart.md) und [OBS](live-event-obs-quickstart.md) zur Verfügung. Wenn Sie lieber mit einer Übersicht von Media Services-Liveereignissen beginnen möchten, finden Sie weitere Informationen unter [Liveereignistypen](stream-live-streaming-concept.md#live-event-types).
  - question: Wie führe ich eine Livetranskription mit einem Media Services-Liveereignis durch?
    answer: >
      Azure Media Service übermittelt Video, Audio und Text in verschiedenen Protokollen. Wenn Sie Ihren Livestream mittels MPEG-DASH oder HLS/CMAF veröffentlichen, stellt der Dienst neben den Video- und Audiospuren auch den transkribierten Text im IMSC1.1-kompatiblen TTML-Format bereit. Weitere Informationen finden Sie unter [Livetranskription](live-event-live-transcription-how-to.md).
  - question: Wie kann ich die Integrität meines Liveereignisses überwachen?
    answer: >
      Sie können Liveereignisse überwachen, indem Sie Event Grid-Ereignisse abonnieren. Weitere Informationen finden Sie unter [Event Grid-Ereignisschema](monitoring/media-services-event-schemas.md#live-event-types).

      Sie haben folgende Möglichkeiten:

      * [Abonnieren](monitoring/reacting-to-media-services-events.md) Sie die Ereignisse für [Microsoft.Media.LiveEventEncoderDisconnected](monitoring/media-services-event-schemas.md#liveeventencoderdisconnected) auf Streamebene, und überwachen Sie, ob für einen bestimmten Zeitraum neue Verbindungen eingehen, um Ihr Liveereignis zu beenden und zu löschen.

      * [Abonnieren](monitoring/reacting-to-media-services-events.md) Sie die [Taktereignisse](monitoring/media-services-event-schemas.md#liveeventingestheartbeat) auf Spurebene. Wenn die eingehende Bitrate bei allen Spuren auf 0 fällt oder wenn der letzte Zeitstempel nicht mehr ansteigt, können Sie das Liveereignis sicher beenden. Die Taktereignisse gehen alle 20 Sekunden für jede Spur ein, sodass die Informationsmenge etwas höher ausfallen könnte.
  - question: Kann ich beim Neustart eines Liveereignisses dieselbe Streaming-URL wiederverwenden?
    answer: >
      Nein, Sie können die gleiche Streaming-URL nicht einfach wiederverwenden, wenn Sie ein Liveereignis beenden und neu starten. Jedes Mal, wenn Sie eine neue Liveausgabe (und ein Medienobjekt) erstellen und veröffentlichen, wird eine neue Streaming-URL (GUID) für den neuen Locator verwendet. Auf diese Weise ist sichergestellt, dass es keine Cachekonflikte im Streamingendpunkt und im CDN (Content Delivery Network) gibt. Sie können Streaming-URLs im Voraus vorbereiten (und kennen), da Sie eine bestimmte GUID für den Streaminglocator erzwingen und dann den Manifestnamen für die Liveausgabe festlegen können.


      Angenommen, Sie möchten GUID 1a7ed69e-a361-433d-8a56-29c61872744f für die Liveausgabe verwenden, die Sie morgen erstellen möchten. Wenn der Tag gekommen ist, starten Sie das Liveereignis und erstellen eine Liveausgabe. Sie können sich entscheiden, „conference1“ für das Manifest zu verwenden und die GUID für den Locator zu erzwingen.


      Die Streaming-URL ist vorhersagbar und lautet `http://<youraccountname>-<azureregion>.streaming.media.azure.net/1a7ed69e-a361-433d-8a56-29c61872744f/conference1.ism/manifest`.


      Sie können die gleiche Liveausgabe oder das gleiche Medienobjekt nicht mehrfach wiederverwenden. Stellen Sie sich die Kombination aus Liveausgabe und Medienobjekt als Bandaufzeichnung vor. Nachdem die Liveausgabe im Medienobjekt aufgezeichnet wurde, können Sie sie nicht für eine andere Aufzeichnung wiederverwenden. Wenn Sie dies tun, kommt es zu einem Blobkonflikt oder zu Überschreibungen. Sofern Sie nicht planen, die Blobs im Speicherkonto vollständig zu bereinigen und das CDN ganz zu löschen, treten Probleme auf. Auch dann treten wahrscheinlich noch Probleme auf, da die Fragmente downstream in den Zwischenspeichern von CDN oder Clientgeräten (z. B. im Browsercache) bereits zwischengespeichert wurden.
- name: Verpackung und Bereitstellung
  questions:
  - question: Ich habe ein Video hochgeladen, codiert und veröffentlicht. Warum wird das Video nicht abgespielt, wenn ich versuche, es zu streamen?
    answer: >
      Einer der häufigsten Gründe ist, dass der Streamingendpunkt, von dem Sie die Wiedergabe ausführen möchten, nicht den Status „Wird ausgeführt“ aufweist.
  - question: Was ist ein Media Services-Streamingendpunkt?
    answer: >
      In Media Services stellt ein Streamingendpunkt einen dynamischen (Just-In-Time-)Paketerstellungs- und Ursprungsdienst dar, der Ihre Live- und On-Demand-Inhalte direkt in einer Clientplayer-App bereitstellen kann, indem er eins der allgemeinen Streamingmedienprotokolle (HLS oder DASH) verwendet. Zudem sorgt der Streamingendpunkt für eine dynamische (Just-In-Time-)Verschlüsselung zu branchenführenden DRM-Systemen. Weitere Informationen finden Sie unter [Streamingendpunkte (Ursprung) in Azure Media Services](stream-streaming-endpoint-concept.md).
  - question: Was ist ein Media Services-Streaminglocator?
    answer: >
      Um Videos für die Wiedergabe durch Clients verfügbar zu machen, erstellen Sie einen Streaminglocator und dann die Streaming-URLs. Der Streaminglocator wird außerdem verwendet, um Streamingrichtlinien anzuwenden, die Regeln für die Verwendung der Mediendateien enthalten.
  - question: Wie erstelle ich einen Media Services-Streaminglocator?
    answer: >
      Um eine Streaming-URL zu erstellen, erstellen Sie zunächst einen Streaminglocator. Anschließend verketten Sie den Hostnamen des Streamingendpunkts und den Pfad des Streaminglocators miteinander. Weitere Informationen finden Sie unter [Erstellen eines Streaminglocators und von URLs](create-streaming-locator-build-url.md).
  - question: Was ist eine Streamingrichtlinie?
    answer: >
      Mithilfe von Streamingrichtlinien können Sie Streamingprotokolle und Verschlüsselungsoptionen für Ihren Streaminglocator definieren. Media Services v3 bietet einige vordefinierte Streamingrichtlinien. Weitere Informationen finden Sie unter [Streamingrichtlinien](./stream-streaming-policy-concept.md).
  - question: Wie erstelle ich eine Media Services-Streamingrichtlinie?
    answer: >
      Eine Liste der vordefinierten Richtlinien, die Sie für die ersten Schritte verwenden können, finden Sie unter [Streamingrichtlinien](./stream-streaming-policy-concept.md).
  - question: Wie kann ich Inhalte im HLS-Format auf Apple-Geräte streamen?
    answer: >
      Stellen Sie sicher, dass Sie am Ende Ihres Pfads (nach dem Bereich **/manifest** der URL) **(format=m3u8-cmaf)** verwenden, um den Ursprungsserver des Streamings anzuweisen, HLS-Inhalte für die Nutzung auf nativen Apple iOS-Geräten zurückzugeben. Ausführliche Informationen finden Sie unter [Bereitstellung von Inhalten](encode-dynamic-packaging-concept.md).
  - question: Kann ich vorhandene MP4-Dateien streamen, die in einer anderen Lösung vorcodiert oder codiert sind?
    answer: "Ja, der Media Services-Ursprungsserver (Streamingendpunkt) unterstützt die dynamische Paketerstellung von MP4-Dateien im HLS- oder DASH-Streamingformat. Der Inhalt muss jedoch im Closed-GOP-Format (geschlossene Bildgruppe) codiert werden, mit kurzen GOPs mit einer Dauer von zwei bis sechs Sekunden. Es werden die folgenden Einstellungen empfohlen: GOPs von zwei Sekunden Länge, Keyframeabstand von min. und max. zwei Sekunden, Codierung mit konstanter Bitrate (CBR-Modus). Die meisten Inhalte in diesem Format, die mit dem H264- oder HEVC-Videocodec zusammen mit dem AAC-Audioformat codiert werden, können unterstützt werden. Zusätzliche, vorcodierte Audioformate werden möglicherweise ebenfalls unterstützt, z. B. Dolby DD+. \n\nUm dies zu erreichen, erstellen Sie ein Medienobjekt, laden Sie die vorcodierten Medienobjekte mithilfe von Azure Blob-Storage-Client-SDKs in den Container des Medienobjekts hoch und generieren dann die erforderlichen Servermanifest- (.ism) und Clientmanifestdateien. Einzelheiten finden Sie im .NET-Beispielprojekt [Stream existing MP4 files](https://github.com/Azure-Samples/media-services-v3-dotnet/tree/main/Streaming/StreamExistingMp4) (Streamen vorhandener MP4-Dateien).\n\nBeachten Sie, dass dieser Ansatz Auswirkungen auf die Leistung hat, da der integrierte Encoder in Azure Media Services auch binäre Indizes (MPI-Dateien) generiert, die die Zugriffszeit auf die MP4-Dateien verbessern. Ohne diese Dateien belastet der Server bei hoher Auslastung die CPU möglicherweise etwas stärker. Weitere Informationen finden Sie unter [Streamen einer vorhandenen MP4-Datei mit einheitlicher Bitrate mit HLS oder Dash](https://github.com/Azure-Samples/media-services-v3-dotnet/tree/main/Streaming/StreamExistingMp4).\n\nWenn Sie bei diesem Ansatz zentral hochskalieren, sollten Sie die CPU-Last des Streamingendpunkts überwachen. Wenn Sie planen, mit einer großen Bibliothek von MP4-Dateien, die außerhalb von Azure Media Services vorcodiert wurden, in die Produktion zu gehen, öffnen Sie ein Supportticket, um Ihre Architektur überprüfen zu lassen und nach Möglichkeiten zu fragen, die Leistung des Ursprungsservers der vorcodierten MP4-Inhalte zu verbessern. \n"
- name: Inhaltsschutz
  questions:
  - question: Wie kann ich meine Medieninhalte mit dynamischer Verschlüsselung bereitstellen?
    answer: >
      Die dynamische Verschlüsselung schützt Ihre Medien ab dem Zeitpunkt, an dem sie Ihren Computer verlassen, während des gesamten Prozesses der Speicherung, Verarbeitung und Übermittlung. Mit Media Services können Sie Ihre zu übermittelnden Live- und On-Demand-Inhalte dynamisch mit Advanced Encryption Standard (AES-128) oder einem der drei wichtigsten DRM-Systeme verschlüsseln: Microsoft PlayReady, Google Widevine und Apple FairPlay. Weitere Informationen finden Sie unter [Inhaltsschutz mit der dynamischen Verschlüsselung von Media Services](./drm-content-protection-concept.md).
  - question: Sollte ich eine Verschlüsselung mit unverschlüsseltem AES-128-Schlüssel oder ein DRM-System verwenden?
    answer: >
      Kunden fragen sich oft, ob sie die AES-Verschlüsselung oder ein DRM-System verwenden sollten. Der Hauptunterschied zwischen den beiden Systemen besteht darin, dass bei der AES-Verschlüsselung der Inhaltsschlüssel per TLS an den Client übertragen wird. Der Schlüssel wird während der Übertragung ohne zusätzliche Verschlüsselung („als Klartext“) verschlüsselt. So kann der Schlüssel zur Entschlüsselung des Inhalts für den Clientplayer zugänglich gemacht und in einer Netzwerkablaufverfolgung auf dem Client als unverschlüsselter Text angezeigt werden. Die Verschlüsselung mit einem unverschlüsselten AES-128-Schlüssel eignet sich für Anwendungsfälle, in denen der Betrachter vertrauenswürdig ist (z.B. bei Unternehmensvideos, die innerhalb eines Unternehmens verteilt und von Mitarbeitern angesehen werden).


      DRM-Systeme wie PlayReady, Widevine und FairPlay bieten eine zusätzliche Verschlüsselungsebene für den Schlüssel, der zum Entschlüsseln des Inhalts verwendet wird (im Vergleich zu einem unverschlüsselten AES-128-Schlüssel). Der Inhaltsschlüssel wird zusätzlich zur Verschlüsselung auf Übertragungsebene, die von TLS bereitgestellt wird, mit einem durch die DRM-Runtime geschützten Schlüssel verschlüsselt. Die Entschlüsselung erfolgt in einer sicheren Umgebung auf Betriebssystemebene, wo ein Angriff durch einen böswilligen Benutzer schwieriger auszuführen ist. DRM wird für Anwendungsfälle empfohlen, in denen der Betrachter möglicherweise nicht vertrauenswürdig ist und Sie ein Höchstmaß an Sicherheit benötigen.
  - question: Wie zeige ich ein Video nur für Benutzer mit bestimmten Berechtigungen an, ohne Azure AD zu verwenden?
    answer: >
      Sie müssen keinen bestimmten Tokenanbieter wie Azure Active Directory (Azure AD) verwenden. Sie können einen eigenen [JWT](../../active-directory/develop/security-tokens.md#json-web-tokens-and-claims)-Anbieter (einen sogenannten Sicherheitstokendienst oder STS) erstellen und dabei eine Verschlüsselung mit asymmetrischem Schlüssel verwenden. Sie können in Ihrem benutzerdefinierten Sicherheitstokendienst Ansprüche basierend auf Ihrer Geschäftslogik hinzufügen.


      Stellen Sie sicher, dass der Aussteller, die Zielgruppe und die Ansprüche genau dem Inhalt des JWT und dem Wert `ContentKeyPolicyRestriction` in `ContentKeyPolicy` entsprechen.


      Weitere Informationen finden Sie unter [Inhaltsschutz mit der dynamischen Verschlüsselung von Media Services](drm-content-protection-concept.md).
  - question: Wie und wo kann ich ein JWT-Token abrufen, um damit dann eine Lizenz oder einen Schlüssel anzufordern?
    answer: >
      Für die Produktion benötigen Sie einen Sicherheitstokendienst (Webdienst), der bei einer HTTPS-Anforderung ein JWT-Token ausgibt. Zum Testen können Sie den in der `GetTokenAsync`-Methode angegebenen Code verwenden, der in [Program.cs](https://github.com/Azure-Samples/media-services-v3-dotnet-tutorials/blob/main/AMSV3Tutorials/EncryptWithDRM/Program.cs) definiert ist.


      Nach der Authentifizierung eines Benutzers fordert der Player ein solches Token beim STS an und weist dieses als Wert des Tokens zu. Sie können die [Azure Media Player-API](https://amp.azure.net/libs/amp/latest/docs/) verwenden.


      Ein Beispiel für die Ausführung des STS mit einem symmetrischen oder einem asymmetrischen Schlüssel finden Sie im [JWT-Tool](https://aka.ms/jwt). Ein Beispiel für einen Player, der auf Azure Media Player basiert und ein solches JWT-Token verwendet, finden Sie im [Azure-Medientesttool](https://aka.ms/amtest). (Erweitern Sie den Link **player_settings**, um die Tokeneingabe anzuzeigen.)
  - question: Wie autorisiere ich Anforderungen zum Streamen von Videos mit AES-Verschlüsselung?
    answer: >
      Der richtige Ansatz ist die Nutzung von eines Sicherheitstokendiensts. Fügen Sie im STS je nach Benutzerprofil unterschiedliche Ansprüche hinzu (z. B. „Premium-Benutzer“, „Basic-Benutzer“ oder „Benutzer der kostenlosen Testversion“). Bei unterschiedlichen Ansprüchen in einem JWT kann der Benutzer unterschiedliche Inhalte sehen. Für andere Inhalte oder Medienobjekte weist `ContentKeyPolicyRestriction` den entsprechenden Wert für `RequiredClaims` auf.


      Verwenden Sie die Azure Media Services-APIs für die Konfiguration von Lizenzen/Schlüsselbereitstellungen und die Verschlüsselung Ihrer Objekte (siehe [dieses Beispiel](https://github.com/Azure-Samples/media-services-v3-dotnet-tutorials/blob/main/AMSV3Tutorials/EncryptWithAES/Program.cs)).


      Weitere Informationen finden Sie unter


      - [Übersicht über den Inhaltsschutz](drm-content-protection-concept.md)

      - [Entwurf eines Multi-DRM-Inhaltsschutzsystems mit Zugriffssteuerung](architecture-design-multi-drm-system.md)
  - question: Warum wird nur Audio, aber kein Video wiedergegeben, wenn ich den FairPlay-Offlinemodus verwende?
    answer: "Dieses Verhalten scheint durch den Entwurf der Beispielanwendung bedingt zu sein. Wenn ein alternativer Audiotitel vorhanden ist (was bei HLS der Fall ist), verwenden sowohl iOS 10 als auch iOS 11 im Offlinemodus standardmäßig den alternativen Audiotitel. Um dieses Verhalten im FPS-Offlinemodus zu kompensieren, entfernen Sie den alternativen Audiotitel aus dem Datenstrom. Um dies für Media Services zu erreichen, fügen Sie den dynamischen Manifestfilter **audio-only=false** hinzu. Eine HLS-URL endet somit mit **.ism/manifest(format=m3u8-aapl,audio-only=false)** . \n"
  - question: Warum gibt FairPlay offline nur Audiodaten ohne Videomodus wieder, nachdem ich „audio-only=false“ hinzugefügt habe?
    answer: >
      Je nach Cacheschlüsseldesign für das Content Delivery Network wird der Inhalt möglicherweise zwischengespeichert. Löschen Sie den Cacheinhalt.
  - question: Wie sieht die Struktur der heruntergeladenen bzw. Offlinedateien auf iOS-Geräten aus?
    answer: "Die heruntergeladene Dateistruktur auf einem iOS-Gerät sieht aus wie auf dem folgenden Screenshot. Im Ordner *_keys* sind heruntergeladene FPS-Lizenzen gespeichert, wobei für jeden Lizenzdiensthost eine Speicherdatei verwendet wird. Im Ordner *.movpkg* sind Audio- und Videoinhalte gespeichert. \n\nDer erste Ordner mit einem Namen, der mit einem Bindestrich gefolgt von einer Zahl endet, weist Videoinhalte auf. Der numerische Wert ist die Spitzenbandbreite der Videowiedergabe. Der zweite Ordner mit einem Namen, der mit einem Bindestrich endet, auf den „0“ folgt, enthält Audioinhalte. Der dritte Ordner namens *Data* enthält die Hauptwiedergabeliste der FPS-Inhalte. Schließlich enthält *boot.xml* eine vollständige Beschreibung des Inhalts des Ordners *.movpkg*. \n\n![Screenshot: Offlinedateistruktur für die FairPlay iOS-Beispiel-App.](media/drm-offline-fairplay-for-ios-concept/offline-fairplay-file-structure.png)\n\nBeispiel für die Datei „boot.xml“:\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<HLSMoviePackage xmlns:xsi=\"https://www.w3.org/2001/XMLSchema-instance\" xmlns=\"http://apple.com/IMG/Schemas/HLSMoviePackage\" xsi:schemaLocation=\"http://apple.com/IMG/Schemas/HLSMoviePackage /System/Library/Schemas/HLSMoviePackage.xsd\">\n  <Version>1.0</Version>\n  <HLSMoviePackageType>PersistedStore</HLSMoviePackageType>\n  <Streams>\n    <Stream ID=\"1-4DTFY3A3VDRCNZ53YZ3RJ2NPG2AJHNBD-0\" Path=\"1-4DTFY3A3VDRCNZ53YZ3RJ2NPG2AJHNBD-0\" NetworkURL=\"https://willzhanmswest.streaming.mediaservices.windows.net/e7c76dbb-8e38-44b3-be8c-5c78890c4bb4/MicrosoftElite01.ism/QualityLevels(127000)/Manifest(aac_eng_2_127,format=m3u8-aapl)\">\n      <Complete>YES</Complete>\n    </Stream>\n    <Stream ID=\"0-HC6H5GWC5IU62P4VHE7NWNGO2SZGPKUJ-310656\" Path=\"0-HC6H5GWC5IU62P4VHE7NWNGO2SZGPKUJ-310656\" NetworkURL=\"https://willzhanmswest.streaming.mediaservices.windows.net/e7c76dbb-8e38-44b3-be8c-5c78890c4bb4/MicrosoftElite01.ism/QualityLevels(161000)/Manifest(video,format=m3u8-aapl)\">\n      <Complete>YES</Complete>\n    </Stream>\n  </Streams>\n  <MasterPlaylist>\n    <NetworkURL>https://willzhanmswest.streaming.mediaservices.windows.net/e7c76dbb-8e38-44b3-be8c-5c78890c4bb4/MicrosoftElite01.ism/manifest(format=m3u8-aapl,audio-only=false)</NetworkURL>\n  </MasterPlaylist>\n  <DataItems Directory=\"Data\">\n    <DataItem>\n      <ID>CB50F631-8227-477A-BCEC-365BBF12BCC0</ID>\n      <Category>Playlist</Category>\n      <Name>master.m3u8</Name>\n      <DataPath>Playlist-master.m3u8-CB50F631-8227-477A-BCEC-365BBF12BCC0.data</DataPath>\n      <Role>Master</Role>\n    </DataItem>\n  </DataItems>\n</HLSMoviePackage>\n```\n"
  - question: Wie kann ich für einige Clients/Benutzer persistente (offlinefähige) Lizenzen und für andere nicht persistente (nicht offlinefähige) Lizenzen übermitteln? Muss ich den Inhalt duplizieren und separate symmetrische Schlüssel verwenden?
    answer: >
      Da Media Services v3 ein Medienobjekt mit mehreren `StreamingLocator`-Instanzen zulässt, können folgende Elemente zur gleichen Zeit vorhanden sein:


      * Eine `ContentKeyPolicy`-Instanz mit `license_type = "persistent"`, `ContentKeyPolicyRestriction` mit Anspruch auf `"persistent"` und ihre `StreamingLocator`-Instanz.

      * Eine weitere `ContentKeyPolicy`-Instanz mit `license_type="nonpersistent"`, `ContentKeyPolicyRestriction` mit Anspruch auf `"nonpersistent`„ und ihre `StreamingLocator`-Instanz.

      * Zwei `StreamingLocator`-Instanzen mit unterschiedlichen `ContentKey`-Werten.


      Abhängig von der Geschäftslogik des benutzerdefinierten STS werden unterschiedliche Ansprüche im JWT-Token ausgegeben. Mit dem Token kann nur die dazugehörige Lizenz abgerufen und nur die entsprechende URL wiedergegeben werden.
  - question: Wie sieht die Zuordnung zwischen den Sicherheitsstufen von "Widevine" und "Media Services DRM" aus?
    answer: "In der [Widevine DRM-Architekturübersicht](http://www.whymatematica.com/wp-content/uploads/2018/08/Widevine_DRM_Architecture_Overview.pdf) von Google sind drei verschiedene Sicherheitsstufen definiert. In der [Azure Media Services-Dokumentation zur Widevine-Lizenzvorlage](drm-widevine-license-template-concept.md) werden jedoch fünf Sicherheitsstufen (Clientstabilitätsanforderungen für die Wiedergabe) beschrieben.\n\nGoogle Widevine definiert beide Sicherheitsstufen. Der Unterschied besteht in der Nutzungsebene: Architektur oder API. Die fünf Sicherheitsstufen werden in der Widevine-API verwendet. Der Widevine-Lizenzdienst von Azure Media Services deserialisiert das `content_key_specs`-Objekt, das `security_level` enthält, und übergibt es an den globalen Widevine-Übermittlungsdienst. Die folgende Tabelle zeigt die Zuordnung zwischen den beiden Gruppen von Sicherheitsstufen.\n\n| **In der Widevine-Architektur definierte Sicherheitsstufen** |**In der Widevine-API verwendete Sicherheitsstufen**|\n|---|---| \n| **Sicherheitsstufe 1**: Die gesamte Inhaltsverarbeitung, Kryptografie und Kontrolle findet innerhalb der vertrauenswürdigen Ausführungsumgebung (Trusted Execution Environment, TEE) statt. In einigen Implementierungsmodellen findet die Sicherheitsverarbeitung unter Umständen in unterschiedlichen Chips statt.|**security_level=5**: Die Kryptografie, Decodierung und die gesamte Verarbeitung von Medien (komprimiert und unkomprimiert) müssen innerhalb einer hardwaregestützten TEE erfolgen.<br/><br/>**security_level=4**: Die Kryptografie und Decodierung müssen innerhalb einer hardwaregestützten TEE durchgeführt werden.|\n**Sicherheitsstufe 2**: Die Kryptografie (aber nicht die Videoverarbeitung) wird innerhalb der TEE durchgeführt. Entschlüsselte Puffer werden an die Anwendungsdomäne zurückgegeben und über separate Videohardware oder -software verarbeitet. Auf der zweiten Stufe werden Kryptografieinformationen allerdings weiterhin nur innerhalb der TEE verarbeitet.| **security_level=3**: Die zentralen Vorgänge für Daten und Kryptografie müssen innerhalb einer hardwaregestützten TEE ausgeführt werden. |\n| **Sicherheitsstufe 3**: Es gibt keine TEE auf dem Gerät. Zum Schutz der kryptografischen Informationen und entschlüsselten Inhalte können geeignete Maßnahmen im Hostbetriebssystem ergriffen werden. Eine Implementierung der dritten Stufe kann auch ein hardwarebasiertes Kryptografiemodul enthalten. Dadurch wird aber nur die Leistung verbessert, nicht die Sicherheit. | **security_level=2**: Softwarekryptografie und ein verborgener Decoder sind erforderlich.<br/><br/>**security_level=1**: Erfordert softwarebasierte White-Box-Verschlüsselung.|\n"
- name: Überwachung
  questions:
  - question: Wie überwache ich meine Media Services-Ressourcen?
    answer: >
      Verwenden Sie Azure Monitor, um nachzuverfolgen, was mit Ihren Media Services-Ressourcen geschieht. Weitere Informationen finden Sie unter [Überwachen von Media Services](./monitoring/monitor-media-services.md). Schrittanleitungen umfassen das [Überwachen von Media Services-Metriken](./monitoring/media-services-metrics-howto.md) und das [Überwachen von Media Services-Diagnoseprotokollen](./monitoring/media-services-diagnostic-logs-howto.md).
  - question: Wie überwache ich mein Media Services-Liveereignis?
    answer: >
      Verwenden Sie [Azure Event Grid](./monitoring/reacting-to-media-services-events.md), um Ihr Liveereignis ohne einen Abrufdienst zu überwachen. Zu den Schrittanleitungen gehören [Erstellen und Überwachen von Media Services-Ereignissen mit Event Grid mithilfe des Azure-Portals](./monitoring/monitor-events-portal-how-to.md) und [Erstellen und Überwachen von Media Services-Ereignissen mit Event Grid mithilfe der Azure CLI](./monitoring/job-state-events-cli-how-to.md).
- name: Player
  questions:
  - question: Welche Videoplayer kann ich mit Media Services verwenden?
    answer: >
      Media Services funktioniert mit Azure Media Player, Shaka und Video.js. Weitere Informationen finden Sie in der [Azure Media Player-Dokumentation](../azure-media-player/azure-media-player-overview.md) unter [Verwenden des Shaka-Players mit Azure Media Services](./player-shaka-player-how-to.md) oder [Verwenden des Video.js-Players mit Azure Media Services](./player-media-players-concept.md).
- name: Hochverfügbarkeit
  questions:
  - question: Unterstützt Media Services Hochverfügbarkeit?
    answer: >
      Weitere Informationen zu Media Services und Hochverfügbarkeit finden Sie unter [Hochverfügbarkeit bei Media Services und Video on Demand (VoD)](./architecture-high-availability-encoding-concept.md).
- name: Migrieren aus v2
  questions:
  - question: Wie kann ich von Media Services v2 zu Media Services v3 migrieren?
    answer: >
      Wir haben einen [umfassenden Leitfaden für die Migration von v2 zu v3](./migrate-v-2-v-3-migration-introduction.md) erstellt. Wir sind daran interessiert, mehr über Ihre Migrationserfahrung und Ihre Anforderungen zu erfahren. Senden Sie uns daher gerne Ihr Feedback über ein GitHub-Problem oder Supportticket.
- name: Problembehandlung
  questions:
  - question: Wie kann ich herausfinden, was dieser Fehlercode bedeutet?
    answer: >
      Wir haben Fehlercodes in den folgenden Referenzen dokumentiert: [Fehlercodes für Streamingendpunkte](./stream-streaming-endpoint-error-codes-reference.md), [Fehlercodes für Liveereignisse](./live-event-error-codes-reference.md) und [Fehlercodes für Aufträge](./job-error-codes-reference.md). Wenn Sie dort keine Antworten finden, erstellen Sie ein Supportticket.
  - question: Wie kann ich meine Anmeldeinformationen zurücksetzen?
    answer: >
      Sie können [Ihre Kontoanmeldeinformationen mithilfe der Azure-CLI zurücksetzen](./account-reset-account-credentials.md).
- name: Abrechnung und Kostenschätzungen
  questions:
  - question: Wie viel kostet Media Services?
    answer: >
      Weitere Informationen finden Sie unter den [Preisinformationen zu Media Services](https://azure.microsoft.com/pricing/details/media-services/).
- name: Kontingente und Grenzwerte
  questions:
  - question: Welche Kontingente und Grenzwerte gelten für Media Services?
    answer: >
      Weitere Informationen finden Sie unter [Media Services: Kontingente und Grenzwerte](limits-quotas-constraints-reference.md).
- name: Compliance und Kundendaten
  questions:
  - question: Speichert Media Services irgendwelche Kundendaten außerhalb der Dienstregion?
    answer: "Kunden fügen ihren Azure Media Services-Konten ihre eigenen Speicherkonten an. Alle Medienobjektdaten werden in diesen zugeordneten Speicherkonten gespeichert, und der Kunde steuert den Standort und den Replikationstyp dieses Speichers.\n\nZusätzliche Daten, die dem Media Services Konto zugeordnet sind (einschließlich Inhaltsverschlüsselungsschlüssel, Tokenüberprüfungsschlüssel, JobInputHttp-URLs und andere Entitätsmetadaten), werden in Microsoft-eigenem Speicher innerhalb der Region gespeichert, die für das Media Services-Konto ausgewählt ist. \n\nAufgrund der [Anforderungen an die Datenresidenz](https://azure.microsoft.com/global-infrastructure/data-residency/#more-information) in den Regionen „Brasilien, Süden“ und „Asien, Südosten“ werden zusätzliche Kontodaten auf zonenredundante Weise gespeichert und sind in einer einzigen Region enthalten. Für Asien, Südosten, werden alle zusätzlichen Kontodaten in Singapur gespeichert. Für Brasilien, Süden, erfolgt die Speicherung der Daten in Brasilien. In anderen Regionen als „Brasilien, Süden“ und „Asien, Südosten“ können die zusätzlichen Kontodaten auch in Microsoft-eigenem Speicher im [Regionspaar](../../best-practices-availability-paired-regions.md) gespeichert sein.\n          \n"
  - question: Bietet Media Services Hochverfügbarkeit oder Datenreplikation?
    answer: Azure Media Services ist ein regionaler Dienst und bietet keine [Hochverfügbarkeit](architecture-high-availability-encoding-concept.md) oder Datenreplikation. Wir empfehlen Kunden, die diese Features benötigen, eine Lösung mithilfe von Media Services-Konten in mehreren Regionen zu erstellen. Ein Beispiel für das Erstellen einer Lösung für [hohe Verfügbarkeit mit Video on Demand (VoD) von Media Services](./architecture-high-availability-encoding-concept.md) ist als Leitfaden verfügbar.
